import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.ai_sidebar import render_ai_sidebar
render_ai_sidebar()


import streamlit as st
import os
# ã‚«ã‚¹ã‚¿ãƒ CSSèª­ã¿è¾¼ã¿
def load_css():
    css_file = "assets/style.css"
    if os.path.exists(css_file):
        with open(css_file, "r", encoding="utf-8") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
load_css()

from modules.page_guard import require_product

# è£½å“é¸æŠãƒã‚§ãƒƒã‚¯ï¼ˆè£½å“ä¸€è¦§ä»¥å¤–ã§å¿…é ˆï¼‰
require_product()


from modules.data_store import DataStore
from modules.file_parser import FileParser
from modules.image_analyzer import ImageAnalyzer
from modules.ai_provider import AIProvider
from modules.prompt_manager import PromptManager
from modules.settings_manager import SettingsManager
import os
from pathlib import Path
import base64

def render_input_page():
    '''å…¥åŠ›æƒ…å ±ãƒšãƒ¼ã‚¸ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°'''
    st.title('ğŸ“¥ å…¥åŠ›æƒ…å ±')
    
    # STEPè¡¨ç¤ºç”¨ã‚¹ã‚¿ã‚¤ãƒ«
    st.markdown("""
    <style>
    .step-label {
        background: linear-gradient(135deg, #6366F1 0%, #4F46E5 100%);
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 4px;
        font-size: 0.75rem;
        font-weight: 600;
        margin-right: 0.5rem;
        display: inline-block;
    }
    .section-divider {
        border-top: 2px solid #E5E7EB;
        margin: 2rem 0 1rem 0;
        padding-top: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # AIã‚µã‚¤ãƒ‰ãƒãƒ¼è¡¨ç¤º
    
    data_store = DataStore()
    
    # ç¾åœ¨ã®è£½å“IDã‚’å–å¾—
    if 'current_product_id' not in st.session_state:
        st.error("è£½å“IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    product_id = st.session_state['current_product_id']
    
    # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    render_product_images_upload(data_store, product_id)
    render_competitor_analysis(data_store, product_id)
    render_sheets_upload(data_store, product_id)
    render_reference_images_upload(data_store, product_id)

def render_product_images_upload(data_store, product_id):
    '''è£½å“ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">ğŸ“· è£½å“ç”»åƒ</div>', unsafe_allow_html=True)
    
    uploaded_files = st.file_uploader(
        "è£½å“ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['png', 'jpg', 'jpeg'],
        accept_multiple_files=True,
        key="product_images"
    )
    
    if uploaded_files:
        upload_dir = Path(f"data/uploads/{product_id}/product_images").resolve()
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        image_paths = []
        for uploaded_file in uploaded_files:
            file_path = upload_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            image_paths.append(str(file_path))  # çµ¶å¯¾ãƒ‘ã‚¹ã¨ã—ã¦ä¿å­˜
            st.success(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        product = data_store.get_product(product_id)
        if not product:
            product = {}
        
        # æ—¢å­˜ãƒªã‚¹ãƒˆã¨ãƒãƒ¼ã‚¸
        existing_images = product.get('product_images', [])
        for path in image_paths:
            if path not in existing_images:
                existing_images.append(path)
        product['product_images'] = existing_images
        
        # Supabaseã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if data_store.use_supabase:
            remote_urls = product.get('product_image_urls', [])
            # ä»Šå›ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’Sync
            for uploaded_file in uploaded_files:
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’æˆ»ã™
                    uploaded_file.seek(0)
                    file_bytes = uploaded_file.read()
                    remote_path = f"{product_id}/product_images/{uploaded_file.name}"
                    
                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è©¦è¡Œ
                    url = data_store.upload_image(file_bytes, remote_path, bucket_name="lp-generator-images")
                    
                    if url:
                        if url not in remote_urls:
                            remote_urls.append(url)
                            st.toast(f"ã‚¯ãƒ©ã‚¦ãƒ‰ä¿å­˜å®Œäº†: {uploaded_file.name}", icon="â˜ï¸")
                    else:
                        st.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ ({uploaded_file.name})")
                        
                except Exception as e:
                    st.error(f"Upload failed for {uploaded_file.name}: {e}")
            
            product['product_image_urls'] = remote_urls

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
        if data_store.update_product(product_id, product):
            st.success("è£½å“æƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        else:
            st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ç”»åƒã‚’è¡¨ç¤º
    product = data_store.get_product(product_id)
    
    
    # Supabase Storage URLã‚’å„ªå…ˆã—ã¦è¡¨ç¤ºï¼ˆStreamlit Cloudå¯¾å¿œï¼‰
    image_urls = product.get("product_image_urls", []) if product else []
    local_images = product.get("product_images", []) if product else []
    
    if image_urls:
        st.markdown("**ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ç”»åƒ (ã‚¯ãƒ©ã‚¦ãƒ‰):**")
        cols = st.columns(4)
        for i, img_url in enumerate(image_urls):
            with cols[i % 4]:
                # ç”»åƒè¡¨ç¤ºï¼ˆå¤±æ•—ã—ã¦ã‚‚è­¦å‘Šã®ã¿ï¼‰
                try:
                    st.image(img_url, caption=f"Image {i+1}", width="stretch")
                except Exception as e:
                    st.warning(f"èª­è¾¼å¤±æ•—: {e}")
                
                # å‰Šé™¤ãƒœã‚¿ãƒ³ã¯å¸¸ã«è¡¨ç¤º
                if st.button("ğŸ—‘ï¸", key=f"del_prod_img_url_{i}"):
                    if img_url in product.get("product_image_urls", []):
                        product["product_image_urls"].remove(img_url)
                        data_store.update_product(product_id, product)
                        st.rerun()

    elif local_images:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ç”¨ï¼‰
        st.markdown("**ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ç”»åƒ (ãƒ­ãƒ¼ã‚«ãƒ«):**")
        cols = st.columns(4)
        for i, img_path in enumerate(local_images):
            with cols[i % 4]:
                resolved_path = Path(img_path)
                if not resolved_path.is_absolute():
                    resolved_path = Path.cwd() / img_path
                
                if resolved_path.exists():
                    st.image(str(resolved_path), caption=resolved_path.name, width="stretch")
                else:
                    st.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãªã—: {img_path}")
                
                # å‰Šé™¤ãƒœã‚¿ãƒ³ã¯å¸¸ã«è¡¨ç¤º
                if st.button("ğŸ—‘ï¸", key=f"del_prod_img_{i}"):
                    if img_path in product.get("product_images", []):
                        product["product_images"].remove(img_path)
                        data_store.update_product(product_id, product)
                        st.rerun()


def save_competitor_data(product_id, data_store):
    """å…¥åŠ›ä¸­ã®ç«¶åˆãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜ï¼ˆåˆ†æå‰ã®ä¸€æ™‚ä¿å­˜ï¼‰"""
    product = data_store.get_product(product_id) or {}
    current_data = product.get("competitor_analysis_v2", {})
    competitors = current_data.get("competitors", [])
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦æ›´æ–°
    count = st.session_state.get("competitor_count", 1)
    
    # æ—¢å­˜ãƒªã‚¹ãƒˆã¨æ–°ã—ã„ã‚«ã‚¦ãƒ³ãƒˆã®æ•´åˆæ€§ã‚’å–ã‚‹
    new_competitors = []
    for i in range(count):
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å¼•ãç¶™ã
        comp_data = competitors[i] if i < len(competitors) else {}
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æœ€æ–°å€¤ã§ä¸Šæ›¸ã
        comp_data["name"] = st.session_state.get(f"comp_name_{i}", f"ç«¶åˆ{i+1}")
        comp_data["text"] = st.session_state.get(f"comp_text_{i}", "")
        comp_data["files"] = st.session_state.get(f"comp_files_paths_{i}", [])
        
        new_competitors.append(comp_data)
            
    current_data["competitors"] = new_competitors
    product["competitor_analysis_v2"] = current_data
    if data_store.update_product(product_id, product):
        st.toast("ç«¶åˆæƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ", icon="ğŸ’¾")

def render_competitor_analysis(data_store, product_id):
    '''ç«¶åˆæƒ…å ±åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">ğŸ” ç«¶åˆæƒ…å ±</div>', unsafe_allow_html=True)
    st.caption("ç«¶åˆã”ã¨ã«ç”»åƒãƒ»ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ è¨´æ±‚è¦ç´ ã‚’è‡ªå‹•æŠ½å‡º")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ï¼ˆä¿å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å¾©å…ƒï¼‰
    if "competitor_count" not in st.session_state:
        # DBã‹ã‚‰ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        product = data_store.get_product(product_id)
        saved_competitors = []
        if product and "competitor_analysis_v2" in product:
            saved_competitors = product["competitor_analysis_v2"].get("competitors", [])
        
        if saved_competitors:
            st.session_state.competitor_count = len(saved_competitors)
            for i, comp in enumerate(saved_competitors):
                st.session_state[f"comp_name_{i}"] = comp.get("name", f"ç«¶åˆ{i+1}")
                st.session_state[f"comp_text_{i}"] = comp.get("text", "")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å¾©å…ƒï¼ˆæ³¨æ„: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ãªã®ã§ç’°å¢ƒã¾ãŸãã§ã¯è¦‹ãˆãªã„ãŒã€åŒä¸€ç’°å¢ƒãªã‚‰è¦‹ãˆã‚‹ï¼‰
                if "files" in comp:
                    st.session_state[f"comp_files_paths_{i}"] = comp["files"]
        else:
            st.session_state.competitor_count = 1
    
    # ç«¶åˆè¿½åŠ ãƒœã‚¿ãƒ³
    col_add, col_space = st.columns([1, 3])
    with col_add:
        if st.button("â• ç«¶åˆã‚’è¿½åŠ ", key="add_competitor"):
            if st.session_state.competitor_count < 10:
                st.session_state.competitor_count += 1
                st.rerun()
            else:
                st.warning("æœ€å¤§10ç¤¾ã¾ã§ã§ã™")
    
    st.markdown("---")
    
    # å„ç«¶åˆã®å…¥åŠ›ã‚¨ãƒªã‚¢
    for i in range(st.session_state.competitor_count):
        with st.expander(f"ğŸ¢ ç«¶åˆ{i+1}", expanded=False):
            # ã‚­ãƒ¼ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®æº–å‚™
            name_key = f"comp_name_{i}"
            default_name = f"ç«¶åˆ{i+1}"
            if name_key not in st.session_state:
                st.session_state[name_key] = default_name

            comp_name = st.text_input(
                "ç«¶åˆå",
                # valueå¼•æ•°ã¯å‰Šé™¤ï¼ˆsession_stateå„ªå…ˆï¼‰
                key=name_key,
                placeholder="ä¾‹: Aç¤¾ã€Bç¤¾",
                on_change=save_competitor_data,
                args=(product_id, data_store)
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ğŸ“ ç”»åƒï¼ˆæœ€å¤§30æšï¼‰**")
                
                # ä¿å­˜æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
                saved_dir = Path(f"data/uploads/{product_id}/competitors/comp_{i}")
                saved_files = []
                if saved_dir.exists():
                    saved_files = list(saved_dir.glob("*.jpg")) + list(saved_dir.glob("*.jpeg")) + list(saved_dir.glob("*.png"))
                    saved_files = [str(f) for f in saved_files]
                
                uploaded_files = st.file_uploader(
                    "LPç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                    type=['png', 'jpg', 'jpeg'],
                    accept_multiple_files=True,
                    key=f"comp_files_{i}",
                    label_visibility="collapsed"
                )
                
                if uploaded_files:
                    if len(uploaded_files) > 30:
                        st.warning("æœ€å¤§30æšã¾ã§ã§ã™")
                        uploaded_files = uploaded_files[:30]
                    
                    upload_dir = Path(f"data/uploads/{product_id}/competitors/comp_{i}")
                    upload_dir.mkdir(parents=True, exist_ok=True)
                    
                    file_paths = []
                    for uf in uploaded_files:
                        file_path = upload_dir / uf.name
                        with open(file_path, "wb") as f:
                            f.write(uf.getbuffer())
                        file_paths.append(str(file_path))
                    
                    st.success(f"{len(file_paths)}æšã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿")
                    st.session_state[f"comp_files_paths_{i}"] = file_paths
                    saved_files = file_paths  # æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å„ªå…ˆ
                
                # ä¿å­˜æ¸ˆã¿ or æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’è¡¨ç¤º
                if saved_files:
                    st.session_state[f"comp_files_paths_{i}"] = saved_files
                    st.caption(f"ğŸ“· {len(saved_files)}æš")
                    preview_cols = st.columns(6)
                    for idx, fp in enumerate(saved_files[:6]):
                        with preview_cols[idx % 6]:
                            st.image(fp, width=80)
                    if len(saved_files) > 6:
                        st.caption(f"ä»– {len(saved_files) - 6}æš")
            
                # ã‚­ãƒ¼ã®æº–å‚™
                text_key = f"comp_text_{i}"
                if text_key not in st.session_state:
                    st.session_state[text_key] = ""

                comp_text = st.text_area(
                    "ç«¶åˆã®LPæƒ…å ±ã‚’ã‚³ãƒ”ãƒš",
                    height=150,
                    key=text_key,
                    placeholder="ç«¶åˆå•†å“ãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±ã‚’ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆ...",
                    label_visibility="collapsed",
                    on_change=save_competitor_data,
                    args=(product_id, data_store)
                )
    
    st.markdown("---")
    
    # ä¸€æ‹¬åˆ†æãƒœã‚¿ãƒ³
    if st.button("ğŸ” ä¸€æ‹¬åˆ†æ", type="primary", width="stretch", key="analyze_all_competitors"):
        analyze_all_competitors(product_id, data_store)
    
    # åˆ†æçµæœè¡¨ç¤º
    product = data_store.get_product(product_id)
    if product and product.get("competitor_analysis_v2"):
        st.markdown("---")
        render_competitor_analysis_results(product["competitor_analysis_v2"])


def organize_keyword_data(product, data_store, product_id):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦åº¦é †ã«æ•´ç†"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.trace_viewer import save_with_trace
    
    with st.spinner("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¦åº¦ã‚’åˆ†æä¸­..."):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—åŒ–
            sheet_data = product.get("review_sheet_data", {})
            raw_text = ""
            if isinstance(sheet_data, dict):
                data_type = sheet_data.get("type", "")
                sheet_content = sheet_data.get("content", "")
                
                if data_type in ["pdf", "text"]:
                    raw_text = str(sheet_content)
                elif isinstance(sheet_content, list):
                    for item in sheet_content:
                        if isinstance(item, dict):
                            for k, v in item.items():
                                if v and str(v) not in ['nan', 'NaN', 'None', '']:
                                    raw_text += f"{k}: {v}\n"
                else:
                    raw_text = str(sheet_content)
            else:
                raw_text = str(sheet_data)
            
            prompt = prompt_manager.get_prompt("keyword_organize", {
                "raw_data": raw_text[:3000]
            })
            
            result = ai_provider.ask(prompt, "keyword_organize")
            
            traced = save_with_trace(
                result=result,
                prompt_id="keyword_organize",
                prompt_used=prompt,
                input_refs={"ãƒ•ã‚¡ã‚¤ãƒ«": product.get("review_sheet", "")},
                model=settings.get("llm_model", "unknown")
            )
            
            product["keyword_organized"] = result
            product["keyword_organize_trace"] = traced
            data_store.update_product(product_id, product)
            
            st.success("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æå®Œäº†ï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")


def organize_sheet_data(product, data_store, product_id):
    """ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’AIã§æ•´ç†"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.trace_viewer import save_with_trace
    
    with st.spinner("ã‚·ãƒ¼ãƒˆå†…å®¹ã‚’æ•´ç†ä¸­..."):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—åŒ–
            sheet_data = product.get("product_sheet_data", {})
            raw_text = ""
            if isinstance(sheet_data, dict):
                data_type = sheet_data.get("type", "")
                content = sheet_data.get("content", "")
                
                if data_type in ["pdf", "text"]:
                    # PDF/ãƒ†ã‚­ã‚¹ãƒˆã¯ãã®ã¾ã¾
                    raw_text = str(content)
                elif isinstance(content, list):
                    # CSV/Excelã¯ãƒªã‚¹ãƒˆå½¢å¼
                    for item in content:
                        if isinstance(item, dict):
                            for k, v in item.items():
                                if v and str(v) not in ['nan', 'NaN', 'None', '']:
                                    raw_text += f"{k}: {v}\n"
                else:
                    raw_text = str(content)
            else:
                raw_text = str(sheet_data)
            
            prompt = prompt_manager.get_prompt("sheet_organize", {
                "raw_data": raw_text[:3000]
            })
            
            result = ai_provider.ask(prompt, "sheet_organize")
            
            # ãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãã§ä¿å­˜
            traced = save_with_trace(
                result=result,
                prompt_id="sheet_organize",
                prompt_used=prompt,
                input_refs={"ãƒ•ã‚¡ã‚¤ãƒ«": product.get("product_sheet", "")},
                model=settings.get("llm_model", "unknown")
            )
            
            product["product_sheet_organized"] = result
            product["product_sheet_organize_trace"] = traced
            data_store.update_product(product_id, product)
            
            st.success("æ•´ç†å®Œäº†ï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"æ•´ç†ã‚¨ãƒ©ãƒ¼: {e}")


def analyze_competitor_text(text, product_id, data_store):
    '''ç«¶åˆãƒ†ã‚­ã‚¹ãƒˆã‚’AIã§åˆ†æ'''
    from modules.trace_viewer import save_with_trace
    with st.spinner('ç«¶åˆæƒ…å ±ã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            prompt = prompt_manager.get_prompt("competitor_analysis", {
                "competitor_text": text
            })
            
            result = ai_provider.ask(prompt, "competitor_analysis")
            
            # ãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãã§ä¿å­˜
            traced_result = save_with_trace(
                result=result,
                prompt_id="competitor_analysis",
                prompt_used=prompt,
                input_refs={"ç«¶åˆãƒ†ã‚­ã‚¹ãƒˆ": text[:200] + "..." if len(text) > 200 else text},
                model=settings.get("llm_model", settings.get("llm_provider", "unknown"))
            )
            
            product = data_store.get_product(product_id)
            if not product:
                product = {}
            product['competitor_analysis'] = traced_result
            data_store.update_product(product_id, product)
            
            st.success("åˆ†æå®Œäº†ï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def analyze_competitor_files(file_paths, product_id, data_store):
    '''ç«¶åˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPDF/ç”»åƒï¼‰ã‚’AIã§åˆ†æ'''
    with st.spinner('ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            
            all_analysis = []
            
            for file_path in file_paths:
                if file_path.lower().endswith('.pdf'):
                    # PDFã®å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                    file_parser = FileParser()
                    text = file_parser.parse(file_path)
                    if text:
                        prompt = f"""ä»¥ä¸‹ã®PDFæ–‡æ›¸ã®å†…å®¹ã‚’åˆ†æã—ã¦ã€ç«¶åˆå•†å“ã®æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

{text}

ã€å‡ºåŠ›å½¢å¼ã€‘
- è£½å“ã®ç‰¹å¾´
- ä¾¡æ ¼æƒ…å ±ï¼ˆã‚ã‚Œã°ï¼‰
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¡§å®¢
- è¨´æ±‚ãƒã‚¤ãƒ³ãƒˆ"""
                        result = ai_provider.generate_text(prompt)
                        all_analysis.append(f"ğŸ“„ {os.path.basename(file_path)}:\n{result}")
                
                elif file_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                    # ç”»åƒã®å ´åˆã¯Vision APIã§åˆ†æ
                    prompt_manager = PromptManager()
                    image_analyzer = ImageAnalyzer(ai_provider, prompt_manager)
                    result = image_analyzer.analyze_image(file_path)
                    all_analysis.append(f"ğŸ–¼ï¸ {os.path.basename(file_path)}:\n{result}")
            
            if all_analysis:
                combined_analysis = "\n\n---\n\n".join(all_analysis)
                
                # çµæœã‚’ä¿å­˜
                product = data_store.get_product(product_id)
                if not product:
                    product = {}
                product['competitor_analysis'] = combined_analysis
                data_store.update_product(product_id, product)
                
                st.success("åˆ†æå®Œäº†ï¼")
                st.rerun()
            else:
                st.warning("åˆ†æã§ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def analyze_all_competitors(product_id, data_store):
    """å…¨ç«¶åˆã‚’ä¸€æ‹¬åˆ†æï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºä»˜ãï¼‰"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.image_analyzer import ImageAnalyzer
    
    try:
        settings_manager = SettingsManager()
        settings = settings_manager.get_settings()
        ai_provider = AIProvider(settings)
        prompt_manager = PromptManager()
        image_analyzer = ImageAnalyzer(ai_provider, prompt_manager)
        
        # åˆ†æå¯¾è±¡ã‚’åé›†
        targets = []
        for i in range(st.session_state.competitor_count):
            comp_name = st.session_state.get(f"comp_name_{i}", f"ç«¶åˆ{i+1}")
            file_paths = st.session_state.get(f"comp_files_paths_{i}", [])
            comp_text = st.session_state.get(f"comp_text_{i}", "")
            
            if file_paths or comp_text.strip():
                targets.append({
                    "name": comp_name,
                    "files": file_paths,
                    "text": comp_text
                })
        
        if not targets:
            st.warning("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        results = []
        for idx, target in enumerate(targets):
            status_text.text(f"åˆ†æä¸­: {target['name']} ({idx+1}/{len(targets)})")
            progress_bar.progress((idx) / len(targets))
            
            result = image_analyzer.analyze_competitor(
                target["name"], 
                target["files"], 
                target["text"]
            )
            results.append(result)
        
        progress_bar.progress(1.0)
        status_text.text("é›†è¨ˆä¸­...")
        
        summary = image_analyzer.summarize_all_competitors(results)
        
        analysis_data = {
            "competitors": results,
            "summary": summary
        }
        
        product = data_store.get_product(product_id)
        if not product:
            product = {}
        product["competitor_analysis_v2"] = analysis_data
        data_store.update_product(product_id, product)
        
        status_text.empty()
        progress_bar.empty()
        st.success(f"{len(results)}ç¤¾ã®ç«¶åˆã‚’åˆ†æã—ã¾ã—ãŸ")
        st.rerun()
    
    except Exception as e:
        st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")


def render_competitor_analysis_results(analysis_data):
    """ç«¶åˆåˆ†æçµæœã‚’è¡¨ç¤º"""
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">ğŸ“Š åˆ†æçµæœ</div>', unsafe_allow_html=True)
    
    competitors = analysis_data.get("competitors", [])
    summary = analysis_data.get("summary", {})
    
    # å„ç«¶åˆã®çµæœ
    for comp in competitors:
        name = comp.get("name", "ä¸æ˜")
        img_count = comp.get("image_count", 0)
        has_text = comp.get("has_text", False)
        elements = comp.get("elements", [])
        
        source_info = []
        if img_count > 0:
            source_info.append(f"ç”»åƒ{img_count}æš")
        if has_text:
            source_info.append("ãƒ†ã‚­ã‚¹ãƒˆ")
        
        st.markdown(f"**â–  {name}** ({', '.join(source_info)})")
        if elements:
            st.markdown(", ".join(elements))
        else:
            st.markdown("_è¦ç´ ãªã—_")
        st.markdown("")
    
    # å…¨ä½“ã‚µãƒãƒªãƒ¼
    if summary.get("element_ranking"):
        st.markdown("---")
        st.subheader("ğŸ† å…¨ç«¶åˆã®è¨´æ±‚è¦ç´ ã¾ã¨ã‚")
        
        total = summary.get("total_competitors", 1)
        
        for elem, count in summary["element_ranking"]:
            if count == total:
                st.markdown(f"âœ… **{elem}** ({count}/{total}ç¤¾) â† å¿…é ˆ")
            elif count >= total * 0.5:
                st.markdown(f"âœ“ {elem} ({count}/{total}ç¤¾)")
            else:
                st.markdown(f"ãƒ» {elem} ({count}/{total}ç¤¾)")


def save_product_sheet(product_id, data_store):
    product = data_store.get_product(product_id)
    if product and "edit_organized" in st.session_state:
        product["product_sheet_organized"] = st.session_state.edit_organized
        if data_store.update_product(product_id, product):
            st.toast("è£½å“ã‚·ãƒ¼ãƒˆæƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ", icon="ğŸ’¾")

def save_keyword_sheet(product_id, data_store):
    product = data_store.get_product(product_id)
    if product and "edit_keyword" in st.session_state:
        product["keyword_organized"] = st.session_state.edit_keyword
        if data_store.update_product(product_id, product):
            st.toast("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ", icon="ğŸ’¾")

def render_sheets_upload(data_store, product_id):
    '''å„ç¨®ã‚·ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        product_sheet = st.file_uploader(
            "è£½å“æƒ…å ±ã‚·ãƒ¼ãƒˆ",
            type=['xlsx', 'csv', 'pdf'],
            key="product_sheet"
        )
        
        if product_sheet:
            upload_dir = Path(f"data/uploads/{product_id}/sheets")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = upload_dir / f"product_sheet_{product_sheet.name}"
            with open(file_path, "wb") as f:
                f.write(product_sheet.getbuffer())
            
            file_parser = FileParser()
            try:
                parsed_data = file_parser.parse(str(file_path))
                
                product = data_store.get_product(product_id)
                if not product:
                    product = {}
                product['product_sheet'] = str(file_path)
                product['product_sheet_data'] = parsed_data
                data_store.update_product(product_id, product)
                
                st.success("è£½å“æƒ…å ±ã‚·ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿è¡¨ç¤º
        product = data_store.get_product(product_id)
        if product and product.get('product_sheet'):
            col_info, col_del = st.columns([4, 1])
            with col_info:
                st.info(f"ğŸ“„ {Path(product['product_sheet']).name}")
            with col_del:
                if st.button("ğŸ—‘ï¸", key="del_product_sheet", help="å‰Šé™¤"):
                    product['product_sheet'] = None
                    product['product_sheet_data'] = None
                    product['product_sheet_organized'] = None
                    data_store.update_product(product_id, product)
                    st.rerun()
            
            # æ•´ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¡¨ç¤º
            organized = product.get("product_sheet_organized", "")
            if organized:
                st.success("âœ… æ•´ç†æ¸ˆã¿")
                with st.expander("ğŸ“‹ æ•´ç†æ¸ˆã¿å†…å®¹ã‚’ç¢ºèªãƒ»ç·¨é›†", expanded=False):
                    edited = st.text_area("å†…å®¹", value=organized, height=300, key="edit_organized", on_change=save_product_sheet, args=(product_id, data_store))
                    col_a, col_b = st.columns(2)
                    with col_a:
                        if st.button("ğŸ’¾ å¤‰æ›´ã‚’ä¿å­˜", key="save_organized"):
                            product["product_sheet_organized"] = edited
                            data_store.update_product(product_id, product)
                            st.success("ä¿å­˜ã—ã¾ã—ãŸ")
                            st.rerun()
                    with col_b:
                        if st.button("ğŸ”„ å†æ•´ç†ï¼ˆAIï¼‰", key="reorganize_sheet"):
                            organize_sheet_data(product, data_store, product_id)
            else:
                # æ•´ç†ãƒœã‚¿ãƒ³
                if st.button("ğŸ“‹ å†…å®¹ã‚’æ•´ç†ï¼ˆAIï¼‰", key="organize_sheet"):
                    organize_sheet_data(product, data_store, product_id)
    
    with col2:
        review_sheet = st.file_uploader(
            "ç«¶åˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆ",
            type=['xlsx', 'csv', 'pdf'],
            key="review_sheet"
        )
        
        if review_sheet:
            upload_dir = Path(f"data/uploads/{product_id}/sheets")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = upload_dir / f"review_sheet_{review_sheet.name}"
            with open(file_path, "wb") as f:
                f.write(review_sheet.getbuffer())
            
            file_parser = FileParser()
            try:
                parsed_data = file_parser.parse(str(file_path))
                
                product = data_store.get_product(product_id)
                if not product:
                    product = {}
                product['review_sheet'] = str(file_path)
                product['review_sheet_data'] = parsed_data
                data_store.update_product(product_id, product)
                
                st.success("ç«¶åˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿è¡¨ç¤º
        product = data_store.get_product(product_id)
        if product and product.get("review_sheet"):
            col_info, col_del = st.columns([4, 1])
            with col_info:
                st.info(f"ğŸ“„ {Path(product['review_sheet']).name}")
            with col_del:
                if st.button("ğŸ—‘ï¸", key="del_review_sheet", help="å‰Šé™¤"):
                    product['review_sheet'] = None
                    product['review_sheet_data'] = None
                    product['keyword_organized'] = None
                    data_store.update_product(product_id, product)
                    st.rerun()
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•´ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¡¨ç¤º
            keyword_org = product.get("keyword_organized", "")
            if keyword_org:
                st.success("âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•´ç†æ¸ˆã¿")
                with st.expander("ğŸ“Š ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¦åº¦ï¼ˆç¢ºèªãƒ»ç·¨é›†ï¼‰", expanded=False):
                    edited = st.text_area("å†…å®¹", value=keyword_org, height=300, key="edit_keyword", on_change=save_keyword_sheet, args=(product_id, data_store))
                    col_a, col_b = st.columns(2)
                    with col_a:
                        if st.button("ğŸ’¾ ä¿å­˜", key="save_keyword"):
                            product["keyword_organized"] = edited
                            data_store.update_product(product_id, product)
                            st.success("ä¿å­˜ã—ã¾ã—ãŸ")
                            st.rerun()
                    with col_b:
                        if st.button("ğŸ”„ å†åˆ†æ", key="reanalyze_keyword"):
                            organize_keyword_data(product, data_store, product_id)
            else:
                if st.button("ğŸ“Š ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¦åº¦ã‚’åˆ†æ", key="analyze_keyword"):
                    organize_keyword_data(product, data_store, product_id)



def handle_lp_upload(product_id, data_store):
    """å‚è€ƒLPç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
    if "uploader_key_lp" not in st.session_state:
        st.session_state.uploader_key_lp = 0
    
    key = f"lp_images_{st.session_state.uploader_key_lp}"
    lp_images = st.session_state.get(key)
    
    if lp_images:
        upload_dir = Path(f"data/uploads/{product_id}/reference_lp")
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        image_paths = []
        for uploaded_file in lp_images:
            file_path = upload_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            image_paths.append(str(file_path))
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ã§ã®st.successç­‰ã¯æ¬¡å›ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ã«æ¶ˆãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚toastã‚’ä½¿ç”¨
            st.toast(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
        
        # æœ€æ–°ã®è£½å“æƒ…å ±ã‚’å–å¾—
        product = data_store.get_product(product_id) or {}
        
        # æ—¢å­˜ã®ç”»åƒãƒªã‚¹ãƒˆã«è¿½åŠ 
        existing = product.get('reference_lp_images', [])
        for path in image_paths:
            if path not in existing:
                existing.append(path)
        product['reference_lp_images'] = existing
        
        # Supabaseã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if data_store.use_supabase:
            remote_urls = product.get('reference_lp_image_urls', [])
            for uploaded_file in lp_images:
                try:
                    uploaded_file.seek(0)
                    file_bytes = uploaded_file.read()
                    remote_path = f"{product_id}/reference_lp/{uploaded_file.name}"
                    url = data_store.upload_image(file_bytes, remote_path, bucket_name="lp-generator-images")
                    if url and url not in remote_urls:
                        remote_urls.append(url)
                except Exception as e:
                    print(f"Ref Upload failed: {e}")
            product['reference_lp_image_urls'] = remote_urls

        data_store.update_product(product_id, product)
        
        # æ¬¡å›ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ã«ãƒ•ã‚©ãƒ¼ãƒ ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãŸã‚ã«ã‚­ãƒ¼ã‚’æ›´æ–°
        st.session_state.uploader_key_lp += 1


def handle_tone_upload(product_id, data_store):
    """ãƒˆãƒ³ãƒãƒŠç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
    if "uploader_key_tone" not in st.session_state:
        st.session_state.uploader_key_tone = 0
        
    key = f"tone_images_{st.session_state.uploader_key_tone}"
    tone_images = st.session_state.get(key)
    
    if tone_images:
        upload_dir = Path(f"data/uploads/{product_id}/tone_manner")
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        image_paths = []
        for uploaded_file in tone_images:
            file_path = upload_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            image_paths.append(str(file_path))
            st.toast(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
        
        product = data_store.get_product(product_id) or {}
        
        existing = product.get('tone_manner_images', [])
        for path in image_paths:
            if path not in existing:
                existing.append(path)
        product['tone_manner_images'] = existing
        
        if data_store.use_supabase:
            remote_urls = product.get('tone_manner_image_urls', [])
            for uploaded_file in tone_images:
                try:
                    uploaded_file.seek(0)
                    file_bytes = uploaded_file.read()
                    remote_path = f"{product_id}/tone_manner/{uploaded_file.name}"
                    url = data_store.upload_image(file_bytes, remote_path, bucket_name="lp-generator-images")
                    if url and url not in remote_urls:
                        remote_urls.append(url)
                except Exception as e:
                    print(f"Tone Upload failed: {e}")
            product['tone_manner_image_urls'] = remote_urls
        
        data_store.update_product(product_id, product)
        
        st.session_state.uploader_key_tone += 1

def render_reference_images_upload(data_store, product_id):
    '''å‚è€ƒç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">ğŸ–¼ï¸ å‚è€ƒç”»åƒ</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**å‚è€ƒLPç”»åƒ**")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚­ãƒ¼ã‚’ç®¡ç†
        if "uploader_key_lp" not in st.session_state:
            st.session_state.uploader_key_lp = 0
            
        lp_images = st.file_uploader(
            "å‚è€ƒLPç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=['png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            key=f"lp_images_{st.session_state.uploader_key_lp}",
            on_change=handle_lp_upload,
            args=(product_id, data_store)
        )

    
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿å‚è€ƒLPç”»åƒè¡¨ç¤ºï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰URLå„ªå…ˆï¼‰
        product = data_store.get_product(product_id)
        # URLãƒªã‚¹ãƒˆã¨ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ãƒªã‚¹ãƒˆã‚’çµ±åˆã—ã¦è¡¨ç¤ºå¯¾è±¡ã«ã™ã‚‹
        display_images = []
        
        # URLãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆ
        if product and product.get("reference_lp_image_urls"):
            display_images.extend([{"type": "url", "path": url} for url in product["reference_lp_image_urls"]])
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚‚ï¼ˆURLã«å«ã¾ã‚Œã¦ã„ãªã„ã‚‚ã®ãŒã‚ã‚Œã°ï¼‰
        if product and product.get("reference_lp_images"):
            # URLã®ãƒ•ã‚¡ã‚¤ãƒ«åã¨æ¯”è¼ƒã—ã¦é‡è¤‡ã‚’é™¤ãç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯
            url_filenames = [u.split("/")[-1] for u in product.get("reference_lp_image_urls", [])]
            for img in product["reference_lp_images"]:
                if Path(img).name not in url_filenames and Path(img).exists():
                     display_images.append({"type": "local", "path": img})

        if display_images:
            st.markdown("**ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿:**")
            cols = st.columns(4)
            for i, img_info in enumerate(display_images):
                with cols[i % 4]:
                    img_path = img_info["path"]
                    caption_text = Path(img_path).name if img_info["type"] == "local" else img_path.split('/')[-1].split('?')[0]
                    
                    # ç”»åƒè¡¨ç¤ºï¼ˆå¤±æ•—ã—ã¦ã‚‚ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã®ã¿ï¼‰
                    try:
                        st.image(img_path, caption=caption_text, width=100)
                    except Exception as e:
                        st.warning(f"èª­è¾¼å¤±æ•—: {caption_text}")
                    
                    # å‰Šé™¤ãƒœã‚¿ãƒ³ã¯å¸¸ã«è¡¨ç¤ºï¼ˆç”»åƒè¡¨ç¤ºã®æˆå¦ã«é–¢ã‚ã‚‰ãšï¼‰
                    if st.button("ğŸ—‘ï¸", key=f"del_lp_{i}"):
                        # æœ€æ–°ã®è£½å“æƒ…å ±ã‚’å†å–å¾—ã—ã¦å‰Šé™¤å‡¦ç†ã‚’è¡Œã†
                        current_product = data_store.get_product(product_id) or {}
                        target_filename = caption_text
                        
                        # URLãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
                        if "reference_lp_image_urls" in current_product:
                            current_product["reference_lp_image_urls"] = [
                                u for u in current_product["reference_lp_image_urls"] 
                                if u.split('/')[-1].split('?')[0] != target_filename
                            ]
                        
                        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
                        if "reference_lp_images" in current_product:
                            current_product["reference_lp_images"] = [
                                p for p in current_product["reference_lp_images"] 
                                if Path(p).name != target_filename
                            ]
                        
                        data_store.update_product(product_id, current_product)
                        st.rerun()
        
        # LPåˆ†æçµæœè¡¨ç¤º
        from modules.trace_viewer import show_trace
        if product.get("lp_analyses"):
            st.markdown("**ğŸ“Š LPåˆ†æçµæœ:**")
            for i, analysis in enumerate(product["lp_analyses"]):
                with st.expander(f"ğŸ“„ {i+1}æšç›®ã®åˆ†æ", expanded=False):
                    if isinstance(analysis, dict) and "result" in analysis:
                        from modules.trace_viewer import show_lp_analysis
                        show_lp_analysis(analysis)
                        
                        # å†åˆ†æãƒœã‚¿ãƒ³
                        if st.button(f"ğŸ”„ å†åˆ†æ", key=f"reanalyze_lp_{i}"):
                            reanalyze_lp_image(product, data_store, product_id, i)
                        
                        # ç·¨é›†ãƒ¢ãƒ¼ãƒ‰
                        if st.checkbox(f"âœï¸ ç·¨é›†ã™ã‚‹", key=f"edit_lp_{i}"):
                            result = analysis["result"]
                            
                            # ãƒšãƒ¼ã‚¸ç¨®åˆ¥
                            page_types = ["ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼", "æ©Ÿèƒ½èª¬æ˜", "æ¯”è¼ƒè¡¨", "å£ã‚³ãƒŸ", "CTA", "ãã®ä»–"]
                            current_type = result.get("page_type", "ãã®ä»–")
                            idx = page_types.index(current_type) if current_type in page_types else 5
                            new_type = st.selectbox("ãƒšãƒ¼ã‚¸ç¨®åˆ¥", page_types, index=idx, key=f"type_{i}")
                            result["page_type"] = new_type
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ç·¨é›†
                            st.markdown("**ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ **")
                            texts = result.get("texts", [])
                            for j, t in enumerate(texts):
                                cols = st.columns([2, 3, 1])
                                with cols[0]:
                                    t["type"] = st.text_input("ç¨®é¡", t.get("type", ""), key=f"tt_{i}_{j}")
                                with cols[1]:
                                    t["content"] = st.text_input("å†…å®¹", t.get("content", ""), key=f"tc_{i}_{j}")
                                with cols[2]:
                                    if st.button("ğŸ—‘ï¸", key=f"del_t_{i}_{j}"):
                                        texts.pop(j)
                                        data_store.update_product(product_id, product)
                                        st.rerun()
                            
                            if st.button("â• ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ ", key=f"add_t_{i}"):
                                texts.append({"type": "", "content": "", "char_count": 0, "position": "", "size": ""})
                                data_store.update_product(product_id, product)
                                st.rerun()
                            
                            if st.button("ğŸ’¾ ä¿å­˜", key=f"save_lp_{i}", type="primary"):
                                data_store.update_product(product_id, product)
                                st.success("ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
                        show_trace(analysis, f"{i+1}æšç›®ã®ç”Ÿæˆæƒ…å ±")
                    else:
                        st.write(analysis)
    
    with col2:
        st.write("**ãƒˆãƒ³ãƒãƒŠå‚è€ƒç”»åƒ**")
        
        if "uploader_key_tone" not in st.session_state:
            st.session_state.uploader_key_tone = 0
            
        tone_images = st.file_uploader(
            "ãƒˆãƒ³ãƒãƒŠå‚è€ƒç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=['png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            key=f"tone_images_{st.session_state.uploader_key_tone}",
            on_change=handle_tone_upload,
            args=(product_id, data_store)
        )

        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒˆãƒ³ãƒãƒŠç”»åƒè¡¨ç¤ºï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰URLå„ªå…ˆï¼‰
        product = data_store.get_product(product_id)
        tm_display_images = []
        
        if product and product.get("tone_manner_image_urls"):
            tm_display_images.extend([{"type": "url", "path": url} for url in product["tone_manner_image_urls"]])
            
        if product and product.get("tone_manner_images"):
            url_filenames = [u.split("/")[-1] for u in product.get("tone_manner_image_urls", [])]
            for img in product["tone_manner_images"]:
                if Path(img).name not in url_filenames and Path(img).exists():
                     tm_display_images.append({"type": "local", "path": img})

        if tm_display_images:
            st.markdown("**ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿:**")
            cols = st.columns(4)
            for i, img_info in enumerate(tm_display_images):
                with cols[i % 4]:
                    img_path = img_info["path"]
                    caption_text = Path(img_path).name if img_info["type"] == "local" else img_path.split('/')[-1].split('?')[0]
                    
                    # ç”»åƒè¡¨ç¤ºï¼ˆå¤±æ•—ã—ã¦ã‚‚ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã®ã¿ï¼‰
                    try:
                        st.image(img_path, caption=caption_text, width=100)
                    except Exception as e:
                        st.warning(f"èª­è¾¼å¤±æ•—: {caption_text}")
                    
                    # å‰Šé™¤ãƒœã‚¿ãƒ³ã¯å¸¸ã«è¡¨ç¤ºï¼ˆç”»åƒè¡¨ç¤ºã®æˆå¦ã«é–¢ã‚ã‚‰ãšï¼‰
                    if st.button("ğŸ—‘ï¸", key=f"del_tone_{i}"):
                        # æœ€æ–°ã®è£½å“æƒ…å ±ã‚’å†å–å¾—ã—ã¦å‰Šé™¤å‡¦ç†ã‚’è¡Œã†
                        current_product = data_store.get_product(product_id) or {}
                        target_filename = caption_text
                        
                        if "tone_manner_image_urls" in current_product:
                            current_product["tone_manner_image_urls"] = [
                                u for u in current_product["tone_manner_image_urls"] 
                                if u.split('/')[-1].split('?')[0] != target_filename
                            ]
                            
                        if "tone_manner_images" in current_product:
                            current_product["tone_manner_images"] = [
                                p for p in current_product["tone_manner_images"] 
                                if Path(p).name != target_filename
                            ]
                            
                        data_store.update_product(product_id, current_product)
                        st.rerun()
        
        # ãƒˆãƒ³ãƒãƒŠåˆ†æçµæœè¡¨ç¤º
        from modules.trace_viewer import show_trace
        if product and product.get("tone_manner"):
            st.markdown("**ğŸ¨ ãƒˆãƒ³ãƒãƒŠåˆ†æçµæœ:**")
            tone = product["tone_manner"]
            if isinstance(tone, dict) and "result" in tone:
                result = tone["result"]
                
                # ã‚«ãƒ©ãƒ¼è¡¨ç¤º
                colors = result.get("colors", {})
                if colors:
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.color_picker("ãƒ¡ã‚¤ãƒ³", colors.get("main", "#000000"), disabled=True, key="tm_main")
                        st.caption(colors.get("main", ""))
                    with col2:
                        st.color_picker("ã‚¢ã‚¯ã‚»ãƒ³ãƒˆ", colors.get("accent", "#000000"), disabled=True, key="tm_accent")
                        st.caption(colors.get("accent", ""))
                    with col3:
                        st.color_picker("èƒŒæ™¯", colors.get("background", "#FFFFFF"), disabled=True, key="tm_bg")
                        st.caption(colors.get("background", ""))
                    with col4:
                        st.color_picker("ãƒ†ã‚­ã‚¹ãƒˆ", colors.get("text", "#000000"), disabled=True, key="tm_text")
                        st.caption(colors.get("text", ""))
                
                # ãƒ•ã‚©ãƒ³ãƒˆæƒ…å ±
                font = result.get("font", {})
                if font:
                    st.markdown(f"**ãƒ•ã‚©ãƒ³ãƒˆ:** {font.get('type', '')} / {font.get('weight', '')} / {font.get('style', '')}")
                
                # å…¨ä½“ã‚¹ã‚¿ã‚¤ãƒ«
                style = result.get("overall_style", {})
                if style:
                    st.markdown(f"**ã‚¹ã‚¿ã‚¤ãƒ«:** {style.get('impression', '')} / {style.get('target_gender', '')} / {style.get('target_age', '')}")
                
                show_trace(tone, "ãƒˆãƒ³ãƒãƒŠç”Ÿæˆæƒ…å ±")
            else:
                st.write(tone)
    
    
    if st.button("ğŸ¨ ãƒˆãƒ³ãƒãƒŠç”»åƒã‚’åˆ†æ", type="primary", width="stretch"):
        product = data_store.get_product(product_id)
        if product and product.get("tone_manner_images"):
            analyze_tone_manner_images(product["tone_manner_images"], product_id, data_store)
        else:
            st.warning("ãƒˆãƒ³ãƒãƒŠç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    # ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã‚‰ç›´æ¥åˆ†æã‚’å®Ÿè¡Œ
    if st.button('ğŸ” å‚è€ƒç”»åƒã‹ã‚‰æ§‹æˆã‚’åˆ†æ', type='primary', width="stretch", key="btn_analyze_structure"):
        import traceback
        
        st.info("åˆ†æãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")
        product = data_store.get_product(product_id)
        
        # ç”»åƒã‚½ãƒ¼ã‚¹ã®ç‰¹å®šï¼ˆURLã¨ãƒ­ãƒ¼ã‚«ãƒ«ã‚’çµ±åˆï¼‰
        urls = product.get('reference_lp_image_urls', [])
        local = product.get('reference_lp_images', [])
        
        # URLå„ªå…ˆã€ãƒ•ã‚¡ã‚¤ãƒ«åã§é‡è¤‡æ’é™¤ï¼ˆç°¡æ˜“çš„ï¼‰
        seen_names = set()
        image_sources = []
        
        for url in urls:
            name = url.split('/')[-1].split('?')[0]
            if name not in seen_names:
                image_sources.append(url)
                seen_names.add(name)
        
        for path in local:
            name = Path(path).name
            if name not in seen_names:
                image_sources.append(path)
                seen_names.add(name)

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        with st.expander("ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=True):
            st.write(f"Product ID: {product_id}")
            st.write(f"Product Exists: {bool(product)}")
            st.write(f"URLs ({len(urls)}):", urls)
            st.write(f"Local ({len(local)}):", local)
            st.write(f"Final Sources ({len(image_sources)}):", image_sources)

        if not image_sources:
            st.error("âŒ åˆ†æå¯¾è±¡ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        try:
            # ä¾å­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            image_analyzer = ImageAnalyzer(ai_provider, prompt_manager)
            
            # åˆ†æå®Ÿè¡Œ
            st.write(f"å¯¾è±¡ç”»åƒ: {len(image_sources)}æš - åˆ†æä¸­...")
            analyze_reference_images(image_analyzer, image_sources, product_id, data_store)
            
        except Exception as e:
            st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.code(traceback.format_exc())


def analyze_tone_manner_images(image_paths, product_id, data_store):
    """ãƒˆãƒ³ãƒãƒŠç”»åƒã‚’åˆ†æï¼ˆè‰²ãƒ»ãƒ•ã‚©ãƒ³ãƒˆãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰"""
    from modules.trace_viewer import save_with_trace
    from modules.prompt_manager import PromptManager
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    import json
    
    with st.spinner('ãƒˆãƒ³ãƒãƒŠã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # æœ€åˆã®1æšã‚’ä»£è¡¨ã¨ã—ã¦åˆ†æ
            image_path = image_paths[0]
            prompt = prompt_manager.get_prompt("tone_manner_analysis", {})
            
            result = ai_provider.analyze_image(image_path, prompt)
            
            # JSONæŠ½å‡º
            try:
                if "```json" in result:
                    result = result.split("```json")[1].split("```")[0]
                elif "```" in result:
                    result = result.split("```")[1].split("```")[0]
                parsed = json.loads(result.strip())
            except:
                parsed = {"raw": result, "parse_error": True}
            
            # å®Ÿéš›ã«ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ï¼ˆç”»åƒåˆ†æç”¨ï¼‰
            task_models = settings.get("task_models", {})
            used_model = task_models.get("image_analysis", settings.get("llm_model", "unknown"))
            
            traced = save_with_trace(
                result=parsed,
                prompt_id="tone_manner_analysis",
                prompt_used=prompt,
                input_refs={"ç”»åƒ": Path(image_path).name},
                model=used_model
            )
            
            product = data_store.get_product(product_id)
            if not product:
                product = {}
            product['tone_manner'] = traced
            data_store.update_product(product_id, product)
            
            st.success("ãƒˆãƒ³ãƒãƒŠåˆ†æå®Œäº†")
            st.rerun()
            
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")


def reanalyze_lp_image(product, data_store, product_id, index):
    """ç‰¹å®šã®LPç”»åƒã‚’å†åˆ†æ"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.trace_viewer import save_with_trace
    import base64
    import json
    
    with st.spinner(f'{index+1}æšç›®ã‚’å†åˆ†æä¸­...'):
        try:
            lp_images = product.get('reference_lp_images', [])
            if index >= len(lp_images):
                st.error("ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            img_path = lp_images[index]
            
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            prompt = prompt_manager.get_prompt("lp_image_analysis", {})
            
            with open(img_path, "rb") as f:
                img_data = base64.b64encode(f.read()).decode()
            
            result = ai_provider.ask(prompt, "lp_image_analysis", images=[img_data])
            
            if isinstance(result, str):
                result = result.strip()
                if result.startswith("```"):
                    result = result.split("```")[1]
                    if result.startswith("json"):
                        result = result[4:]
                result = json.loads(result)
            
            # å®Ÿéš›ã«ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
            task_models = settings.get("task_models", {})
            used_model = task_models.get("image_analysis", settings.get("llm_model", "unknown"))
            
            traced = save_with_trace(
                result=result,
                prompt_id="lp_image_analysis",
                prompt_used=prompt,
                input_refs={"ç”»åƒ": img_path},
                model=used_model
            )
            
            # æ›´æ–°
            lp_analyses = product.get('lp_analyses') or []
            while len(lp_analyses) <= index:
                lp_analyses.append({})
            lp_analyses[index] = traced
            product['lp_analyses'] = lp_analyses
            data_store.update_product(product_id, product)
            
            st.success("å†åˆ†æå®Œäº†ï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"å†åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def analyze_reference_images(image_analyzer, image_paths, product_id, data_store):
    """å‚è€ƒLPç”»åƒã‚’1æšãšã¤è©³ç´°åˆ†æ"""
    from modules.trace_viewer import save_with_trace
    from modules.prompt_manager import PromptManager
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    import json
    
    with st.spinner('å‚è€ƒLPç”»åƒã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # æ—¢å­˜ã®åˆ†æçµæœã‚’å–å¾—
            product = data_store.get_product(product_id)
            existing_analyses = product.get('lp_analyses_dict', {}) if product else {}
            
            analyses = []
            status_text = st.empty()
            progress_bar = st.progress(0)
            
            for i, image_path in enumerate(image_paths):
                file_name = image_path.split('/')[-1].split('?')[0] if image_path.startswith('http') else Path(image_path).name
                
                # æ—¢ã«åˆ†ææ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
                if file_name in existing_analyses:
                    st.write(f"âœ… åˆ†ææ¸ˆã¿ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰: {file_name}")
                    analyses.append(existing_analyses[file_name])
                    progress_bar.progress((i + 1) / len(image_paths))
                    continue

                status_text.text(f"åˆ†æä¸­: {i+1}/{len(image_paths)}æšç›®... ({file_name})")
                progress_bar.progress((i) / len(image_paths))
                
                # ãƒ‘ã‚¹ã«ã‚ˆã‚‹å­˜åœ¨ç¢ºèªï¼ˆURLã§ãªã„ã€ã‹ã¤ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆï¼‰
                if not image_path.startswith("http") and not os.path.exists(image_path):
                    st.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {Path(image_path).name}")
                    st.warning("ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã¯éå»ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿æŒã•ã‚Œãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãŠæ‰‹æ•°ã§ã™ãŒã€å†åº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ç›´ã—ã¦ãã ã•ã„ã€‚")
                    continue
                
                try:
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
                    prompt = prompt_manager.get_prompt("lp_image_analysis", {})
                    
                    target_path = image_path
                    is_temp = False
                    
                    # URLã®å ´åˆã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    if image_path.startswith("http"):
                        try:
                            import requests
                            import tempfile
                            
                            response = requests.get(image_path, timeout=30)
                            if response.status_code == 200:
                                suffix = "." + image_path.split("/")[-1].split("?")[0].split(".")[-1]
                                if len(suffix) > 5 or "/" in suffix: # æ‹¡å¼µå­å–å¾—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                                    suffix = ".jpg"
                                    
                                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                                    tmp.write(response.content)
                                    target_path = tmp.name
                                    is_temp = True
                            else:
                                st.warning(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆStatus {response.status_code}ï¼‰: {file_name}")
                                continue
                        except Exception as dl_err:
                            st.warning(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {dl_err}")
                            continue

                    # ç”»åƒåˆ†æï¼ˆVision APIï¼‰
                    # ç”»åƒåˆ†æï¼ˆVision APIï¼‰
                    result = ai_provider.analyze_image(target_path, prompt)
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
                    if is_temp and os.path.exists(target_path):
                        try:
                            os.unlink(target_path)
                        except:
                            pass

                    # çµæœãƒã‚§ãƒƒã‚¯
                    if not result:
                        st.warning(f"ç”»åƒåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆçµæœãªã—ï¼‰: {file_name}")
                        continue
                    
                    # JSONæŠ½å‡º
                    try:
                        if "```json" in result:
                            result = result.split("```json")[1].split("```")[0]
                        elif "```" in result:
                            result = result.split("```")[1].split("```")[0]
                        parsed = json.loads(result.strip())
                    except Exception as e:
                        st.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {file_name} - {e}")
                        parsed = {"raw": result, "parse_error": True}
                    
                    # ãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãã§ä¿å­˜
                    traced = save_with_trace(
                        result=parsed,
                        prompt_id="lp_image_analysis",
                        prompt_used=prompt,
                        input_refs={"ç”»åƒ": Path(image_path).name, "é †ç•ª": i+1},
                        model=settings.get("llm_model", "unknown")
                    )
                    
                    # ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    analyses.append(traced)
                    
                    # ã€é‡è¦ã€‘1æšã”ã¨ã«å³æ™‚ä¿å­˜
                    product = data_store.get_product(product_id)
                    if product is None:
                        product = {}

                    current_dict = product.get('lp_analyses_dict')
                    if current_dict is None:
                        current_dict = {}

                    current_dict[file_name] = traced
                    
                    product['lp_analyses_dict'] = current_dict
                    product['lp_analyses'] = list(current_dict.values())
                    
                    if data_store.update_product(product_id, product):
                         existing_analyses[file_name] = traced # ãƒ«ãƒ¼ãƒ—å†…ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚æ›´æ–°
                    else:
                         # ä¿å­˜å¤±æ•—æ™‚ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã•ãšç¶šè¡Œï¼ˆãƒ­ã‚°å‡ºåŠ›ç­‰ã¯æ¤œè¨ï¼‰
                         pass
                         
                except Exception as e:
                    st.warning(f"ç”»åƒåˆ†æã‚¹ã‚­ãƒƒãƒ—ï¼ˆ{Path(image_path).name}ï¼‰: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
                    if 'is_temp' in locals() and is_temp and 'target_path' in locals() and os.path.exists(target_path):
                        try:
                            os.unlink(target_path)
                        except:
                            pass

            # æœ€çµ‚çš„ãªå®Œäº†å‡¦ç†
            st.session_state.processing_reference_analysis = False
            st.success(f"å…¨{len(image_paths)}æšã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
            st.rerun()
                
        except Exception as e:
            st.session_state.processing_reference_analysis = False
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

# ãƒšãƒ¼ã‚¸å®Ÿè¡Œ
render_input_page()
