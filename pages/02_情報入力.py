import streamlit as st
from modules.styles import apply_styles, page_header
from modules.ai_sidebar import render_ai_sidebar

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="Information Input", layout="wide")

# ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨
apply_styles()

# AIã‚µã‚¤ãƒ‰ãƒãƒ¼è¡¨ç¤º
render_ai_sidebar()


import os
from modules.page_guard import require_product

# è£½å“é¸æŠãƒã‚§ãƒƒã‚¯ï¼ˆè£½å“ä¸€è¦§ä»¥å¤–ã§å¿…é ˆï¼‰
require_product()


from modules.data_store import DataStore
from modules.file_parser import FileParser
from modules.image_analyzer import ImageAnalyzer
from modules.ai_provider import AIProvider
from modules.prompt_manager import PromptManager
from modules.settings_manager import SettingsManager
import base64
import uuid
import requests
from pathlib import Path

# æœ‰åŠ¹ãªç”»åƒURLã®ã¿ã‚’è¿”ã™
def get_valid_image_urls(urls):
    """æœ‰åŠ¹ãªç”»åƒURLã®ã¿ã‚’è¿”ã™"""
    if not urls:
        return []
    # æœ‰åŠ¹ãªURLï¼ˆhttpã§å§‹ã¾ã‚‹æ–‡å­—åˆ—ï¼‰ã®ã¿ã‚’æŠ½å‡º
    return [url for url in urls if url and isinstance(url, str) and (url.startswith('http') or url.startswith('/'))]

def render_images_with_bulk_delete(images, image_type, product_id, data_store):
    """ç”»åƒè¡¨ç¤ºã¨ä¸€æ‹¬å‰Šé™¤æ©Ÿèƒ½"""
    
    if not images:
        st.info("ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # æ—¢å­˜ã®è£½å“æƒ…å ±ã‚’å–å¾—
    product = data_store.get_product(product_id)
    if not product:
        st.error("è£½å“æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ãƒãƒƒãƒ”ãƒ³ã‚°
    field_map = {
        "product": {"urls": "product_image_urls", "local": "product_images"},
        "reference_lp": {"urls": "reference_lp_image_urls", "local": "reference_lp_images"},
        "tone_manner": {"urls": "tone_manner_image_urls", "local": "tone_manner_images"}
    }
    fields = field_map.get(image_type)
    if not fields:
        st.error(f"ä¸æ­£ãªç”»åƒã‚¿ã‚¤ãƒ—ã§ã™: {image_type}")
        return

    # ä¸€æ‹¬å‰Šé™¤ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ
    bulk_mode = st.checkbox("ä¸€æ‹¬å‰Šé™¤ãƒ¢ãƒ¼ãƒ‰", key=f"bulk_mode_{image_type}")
    
    if bulk_mode:
        # é¸æŠçŠ¶æ…‹ã‚’ç®¡ç†
        if f"selected_{image_type}" not in st.session_state:
            st.session_state[f"selected_{image_type}"] = []
        
        # å…¨é¸æŠ/å…¨è§£é™¤ãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("å…¨é¸æŠ", key=f"select_all_{image_type}"):
                st.session_state[f"selected_{image_type}"] = list(range(len(images)))
                st.rerun()
        with col2:
            if st.button("å…¨è§£é™¤", key=f"deselect_all_{image_type}"):
                st.session_state[f"selected_{image_type}"] = []
                st.rerun()
        
        # ç”»åƒã‚’ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ä»˜ãï¼‰
        cols = st.columns(4)
        for i, img_info in enumerate(images):
            with cols[i % 4]:
                img_path = img_info["path"]
                # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
                selected = st.checkbox(
                    "é¸æŠ",
                    value=i in st.session_state[f"selected_{image_type}"],
                    key=f"check_{image_type}_{i}"
                )
                if selected and i not in st.session_state[f"selected_{image_type}"]:
                    st.session_state[f"selected_{image_type}"].append(i)
                elif not selected and i in st.session_state[f"selected_{image_type}"]:
                    st.session_state[f"selected_{image_type}"].remove(i)
                
                # ç”»åƒè¡¨ç¤º
                try:
                    st.image(img_path, width=100)
                except:
                    st.caption("âš ï¸ èª­è¾¼å¤±æ•—")
        
        # ä¸€æ‹¬å‰Šé™¤ãƒœã‚¿ãƒ³
        selected_indices = st.session_state[f"selected_{image_type}"]
        selected_count = len(selected_indices)
        if selected_count > 0:
            if st.button(f"é¸æŠã—ãŸ {selected_count} æšã‚’å‰Šé™¤", key=f"bulk_delete_{image_type}", type="primary", use_container_width=True):
                # æœ€æ–°ã®è£½å“æƒ…å ±ã‚’å†å–å¾—
                current_product = data_store.get_product(product_id) or {}
                
                for idx in sorted(selected_indices, reverse=True):
                    img_info = images[idx]
                    path = img_info["path"]
                    filename = Path(path).name if img_info["type"] == "local" else path.split('/')[-1].split('?')[0]
                    
                    # Storageã‹ã‚‰å‰Šé™¤
                    if img_info["type"] == "url":
                        data_store.delete_storage_file(path)
                        if fields["urls"] in current_product:
                            current_product[fields["urls"]].remove(path)
                    
                    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
                    if fields["local"] in current_product:
                        current_product[fields["local"]] = [p for p in current_product[fields["local"]] if Path(p).name != filename]

                    # Reference LP ç‰¹æœ‰ã®å‡¦ç†ï¼ˆåˆ†æçµæœã®å‰Šé™¤ï¼‰
                    if image_type == "reference_lp":
                        if "lp_analyses_dict" in current_product:
                            analyses_dict = current_product["lp_analyses_dict"] or {}
                            if filename in analyses_dict:
                                del analyses_dict[filename]
                            current_product["lp_analyses_dict"] = analyses_dict
                            
                            # lp_analyses ãƒªã‚¹ãƒˆã‚‚å†æ§‹ç¯‰
                            new_lp_analyses = []
                            for local_p in (current_product.get("reference_lp_images") or []):
                                fname = Path(local_p).name
                                if fname in analyses_dict:
                                    new_lp_analyses.append(analyses_dict[fname])
                            current_product["lp_analyses"] = new_lp_analyses
                
                data_store.update_product(product_id, current_product)
                # é¸æŠçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                st.session_state[f"selected_{image_type}"] = []
                st.success(f"{selected_count} æšã®ç”»åƒã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                st.rerun()
    else:
        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆç¾çŠ¶ã®è¡¨ç¤ºï¼‰
        cols = st.columns(4)
        for i, img_info in enumerate(images):
            with cols[i % 4]:
                img_path = img_info["path"]
                filename = Path(img_path).name if img_info["type"] == "local" else img_path.split('/')[-1].split('?')[0]
                try:
                    st.image(img_path, width=100)
                except:
                    st.caption("âš ï¸ èª­è¾¼å¤±æ•—")
                
                if st.button("å‰Šé™¤", key=f"delete_{image_type}_{i}", use_container_width=True):
                    # æœ€æ–°ã®è£½å“æƒ…å ±ã‚’å†å–å¾—
                    current_product = data_store.get_product(product_id) or {}
                    
                    # Storageã‹ã‚‰å‰Šé™¤
                    if img_info["type"] == "url":
                        data_store.delete_storage_file(img_path)
                        if fields["urls"] in current_product:
                            current_product[fields["urls"]].remove(img_path)
                    
                    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
                    if fields["local"] in current_product:
                        current_product[fields["local"]] = [p for p in current_product[fields["local"]] if Path(p).name != filename]

                    # Reference LP ç‰¹æœ‰ã®å‡¦ç†
                    if image_type == "reference_lp":
                        if "lp_analyses_dict" in current_product:
                            analyses_dict = current_product["lp_analyses_dict"] or {}
                            if filename in analyses_dict:
                                del analyses_dict[filename]
                            current_product["lp_analyses_dict"] = analyses_dict
                            new_lp_analyses = []
                            for local_p in (current_product.get("reference_lp_images") or []):
                                fname = Path(local_p).name
                                if fname in analyses_dict:
                                    new_lp_analyses.append(analyses_dict[fname])
                            current_product["lp_analyses"] = new_lp_analyses
                    
                    data_store.update_product(product_id, current_product)
                    st.rerun()

def render_input_page():
    '''å…¥åŠ›æƒ…å ±ãƒšãƒ¼ã‚¸ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°'''
    page_header("Information Input", "ç«¶åˆãƒ»è£½å“æƒ…å ±ã®å…¥åŠ›ã¨åˆ†æ")
    
    # STEPè¡¨ç¤ºç”¨ã‚¹ã‚¿ã‚¤ãƒ«
    st.markdown("""
    <style>
    .step-label {
        background: linear-gradient(135deg, #6366F1 0%, #4F46E5 100%);
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 4px;
        font-size: 0.75rem;
        font-weight: 600;
        margin-right: 0.5rem;
        display: inline-block;
    }
    .section-divider {
        border-top: 2px solid #E5E7EB;
        margin: 2rem 0 1rem 0;
        padding-top: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # AIã‚µã‚¤ãƒ‰ãƒãƒ¼è¡¨ç¤º
    
    data_store = DataStore()
    
    # ç¾åœ¨ã®è£½å“IDã‚’å–å¾—
    if 'current_product_id' not in st.session_state:
        st.error("è£½å“IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    product_id = st.session_state['current_product_id']
    
    # ã‚ªãƒ¼ãƒˆãƒªãƒšã‚¢: å£Šã‚ŒãŸURLã‚’ãƒ­ãƒ¼ãƒ‰æ™‚ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    product = data_store.get_product(product_id)
    if product:
        repaired = False
        for key in ['reference_lp_image_urls', 'tone_manner_image_urls', 'product_image_urls']:
            if key in product:
                original = product[key] or []
                filtered = get_valid_image_urls(original)
                if len(original) != len(filtered):
                    product[key] = filtered
                    repaired = True
        
        if repaired:
            data_store.update_product(product_id, product)
            # st.toast("ä¸æ•´åˆãªç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ä¿®å¾©ã—ã¾ã—ãŸ", icon="ğŸª„")

    # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    render_product_images_upload(data_store, product_id)
    render_competitor_analysis(data_store, product_id)
    render_sheets_upload(data_store, product_id)
    render_reference_images_upload(data_store, product_id)

def render_product_images_upload(data_store, product_id):
    '''è£½å“ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">è£½å“ç”»åƒ</div>', unsafe_allow_html=True)
    
    # å…ˆé ­ã§ product ã‚’å–å¾—
    product = data_store.get_product(product_id) or {}
    
    uploaded_files = st.file_uploader(
        "è£½å“ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['png', 'jpg', 'jpeg'],
        accept_multiple_files=True,
        key="product_images"
    )
    
    if uploaded_files:
        upload_dir = Path(f"data/uploads/{product_id}/product_images").resolve()
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        image_paths = []
        if not data_store.use_supabase:
            for uploaded_file in uploaded_files:
                file_path = upload_dir / uploaded_file.name
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                image_paths.append(str(file_path))  # çµ¶å¯¾ãƒ‘ã‚¹ã¨ã—ã¦ä¿å­˜
                st.success(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–° (æ—¢ã«å…ˆé ­ã§å–å¾—æ¸ˆã¿)
            
            # æ—¢å­˜ãƒªã‚¹ãƒˆã¨ãƒãƒ¼ã‚¸
            existing_images = product.get('product_images') or []
            for path in image_paths:
                if path not in existing_images:
                    existing_images.append(path)
            product['product_images'] = existing_images
        
        # Supabaseã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if data_store.use_supabase:
            remote_urls = product.get('product_image_urls') or []
            # ä»Šå›ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’Sync
            for uploaded_file in uploaded_files:
                try:
                    uploaded_file.seek(0)
                    file_bytes = uploaded_file.read()
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆUUID + æ‹¡å¼µå­ï¼‰
                    ext = uploaded_file.name.split('.')[-1].lower() if '.' in uploaded_file.name else 'jpg'
                    safe_name = f"{uuid.uuid4().hex[:12]}.{ext}"
                    remote_path = f"{product_id}/product_images/{safe_name}"
                    
                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è©¦è¡Œ
                    url = data_store.upload_image(file_bytes, remote_path, bucket_name="lp-generator-images")
                    
                    if url:
                        # æ—¢å­˜URLã«å«ã¾ã‚Œã¦ã„ãªã‘ã‚Œã°è¿½åŠ 
                        if url and url not in remote_urls:
                            remote_urls.append(url)
                            st.toast(f"ã‚¯ãƒ©ã‚¦ãƒ‰ä¿å­˜å®Œäº†: {uploaded_file.name}", icon="â˜ï¸")
                    else:
                        st.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ ({uploaded_file.name})")
                        
                except Exception as e:
                    st.error(f"Upload failed for {uploaded_file.name}: {e}")
            
            # ä¿å­˜å‰ã«é‡è¤‡ã‚’é™¤å»
            remote_urls = list(dict.fromkeys(remote_urls))
            product['product_image_urls'] = remote_urls

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
        if data_store.update_product(product_id, product):
            st.success("è£½å“æƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        else:
            st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ç”»åƒã‚’è¡¨ç¤º
    product = data_store.get_product(product_id)
    
    # è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆã®æ§‹ç¯‰
    display_images = []
    if product:
        # ã‚¯ãƒ©ã‚¦ãƒ‰URL
        image_urls = get_valid_image_urls(product.get("product_image_urls") or [])
        display_images.extend([{"type": "url", "path": url} for url in image_urls])
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ï¼ˆSupabaseæœªä½¿ç”¨æ™‚ã®ã¿ï¼‰
        if not data_store.use_supabase:
            local_images = product.get("product_images") or []
            for path in local_images:
                if Path(path).exists():
                    display_images.append({"type": "local", "path": path})

    if display_images:
        st.markdown("**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ç”»åƒ:**")
        render_images_with_bulk_delete(display_images, "product", product_id, data_store)


def delete_competitor(product_id, data_store, delete_idx):
    """ç«¶åˆã‚’å‰Šé™¤ã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è©°ã‚ç›´ã™"""
    product = data_store.get_product(product_id) or {}
    current_data = product.get("competitor_analysis_v2") or {}
    competitors = current_data.get("competitors") or []
    
    if 0 <= delete_idx < len(competitors):
        # 1. DBãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤
        deleted = competitors.pop(delete_idx)
        
        # 1.5 Storageã‹ã‚‰å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        for url in (deleted.get("file_urls") or []):
            data_store.delete_storage_file(url)
        
        if not competitors:
            # ç«¶åˆãŒ0ã«ãªã£ãŸå ´åˆã¯åˆ†æãƒ‡ãƒ¼ã‚¿å…¨ä½“ã‚’ã‚¯ãƒªã‚¢
            product["competitor_analysis_v2"] = {}
        else:
            # å‰Šé™¤å¾Œã®ãƒªã‚¹ãƒˆã«åŸºã¥ã„ã¦å†é›†è¨ˆï¼ˆAIå‘¼ã³å‡ºã—ãªã—ã§æ¸ˆã¿ã¾ã™ï¼‰
            from modules.image_analyzer import ImageAnalyzer
            # summarize_all_competitorsã¯AIãƒ—ãƒ­ãƒã‚¤ãƒ€ã‚’ä½¿ç”¨ã—ãªã„ãŸã‚Noneã§åˆæœŸåŒ–å¯
            analyzer = ImageAnalyzer(None, None) 
            new_summary = analyzer.summarize_all_competitors(competitors)
            current_data["summary"] = new_summary
            current_data["competitors"] = competitors
            product["competitor_analysis_v2"] = current_data
            
        data_store.update_product(product_id, product)
        
        st.toast(f"ã€Œ{deleted.get('name', 'ç«¶åˆ')}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", icon="ğŸ—‘ï¸")
    
    # 2. Session Stateã®å†æ§‹ç¯‰ï¼ˆè©°ã‚ç›´ã—ï¼‰
    old_count = st.session_state.competitor_count
    new_count = old_count - 1
    
    # å‰Šé™¤å¯¾è±¡ã‚ˆã‚Šå¾Œã‚ã®è¦ç´ ã‚’å‰ã«ãšã‚‰ã™
    for i in range(delete_idx, new_count):
        next_i = i + 1
        st.session_state[f"comp_name_{i}"] = st.session_state.get(f"comp_name_{next_i}", f"ç«¶åˆ{i+1}")
        st.session_state[f"comp_text_{i}"] = st.session_state.get(f"comp_text_{next_i}", "")
        st.session_state[f"comp_files_paths_{i}"] = st.session_state.get(f"comp_files_paths_{next_i}", [])
        st.session_state[f"comp_file_urls_{i}"] = st.session_state.get(f"comp_file_urls_{next_i}", [])
        # uploader_keyã‚‚ãƒªã‚»ãƒƒãƒˆã¾ãŸã¯ç§»å‹•ã•ã›ã‚‹æ–¹ãŒå®‰å…¨ã ãŒã€ã“ã“ã§ã¯æ–°è¦ã‚­ãƒ¼ç™ºè¡Œã‚’ä¿ƒã™ãŸã‚å‰Šé™¤
        if f"uploader_key_comp_{next_i}" in st.session_state:
             st.session_state[f"uploader_key_comp_{i}"] = st.session_state[f"uploader_key_comp_{next_i}"]
    
    # æœ«å°¾ã®è¦ç´ ã‚’å‰Šé™¤
    last_idx = old_count - 1
    keys_to_remove = [
        f"comp_name_{last_idx}", f"comp_text_{last_idx}", 
        f"comp_files_paths_{last_idx}", f"comp_file_urls_{last_idx}",
        f"uploader_key_comp_{last_idx}"
    ]
    for key in keys_to_remove:
        if key in st.session_state:
            del st.session_state[key]
            
    st.session_state.competitor_count = new_count
    st.rerun()


def handle_competitor_upload(product_id, data_store, comp_idx):
    """ç«¶åˆç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
    if f"uploader_key_comp_{comp_idx}" not in st.session_state:
        st.session_state[f"uploader_key_comp_{comp_idx}"] = 0
    
    key = f"comp_files_{comp_idx}_{st.session_state[f'uploader_key_comp_{comp_idx}']}"
    uploaded_files = st.session_state.get(key)
    
    if uploaded_files:
        upload_dir = Path(f"data/uploads/{product_id}/competitors/comp_{comp_idx}")
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        image_paths = []
        if not data_store.use_supabase:
            for uf in uploaded_files:
                file_path = upload_dir / uf.name
                with open(file_path, "wb") as f:
                    f.write(uf.getbuffer())
                image_paths.append(str(file_path))
                st.toast(f"ç«¶åˆ{comp_idx+1}: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­... {uf.name}")
            
            # æœ€æ–°ã®è£½å“æƒ…å ±ã‚’å–å¾—
            product = data_store.get_product(product_id) or {}
            current_data = product.get("competitor_analysis_v2") or {}
            competitors = current_data.get("competitors") or []
            
            # æ•´åˆæ€§ç¢ºä¿ï¼ˆãƒªã‚¹ãƒˆãŒçŸ­ã„å ´åˆã¯æ‹¡å¼µï¼‰
            while len(competitors) <= comp_idx:
                competitors.append({})
            
            comp_data = competitors[comp_idx]
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ä¿å­˜
            existing_files = (comp_data.get("files") or [])
            for path in image_paths:
                if path not in existing_files:
                    existing_files.append(path)
            comp_data["files"] = existing_files
        
        # Supabaseä¿å­˜
        if data_store.use_supabase:
            product = data_store.get_product(product_id) or {} # Re-fetch product if not already fetched for Supabase
            current_data = product.get("competitor_analysis_v2") or {}
            competitors = current_data.get("competitors") or []
            while len(competitors) <= comp_idx:
                competitors.append({})
            comp_data = competitors[comp_idx]

            remote_urls = (comp_data.get("file_urls") or [])
            for uf in uploaded_files:
                try:
                    uf.seek(0)
                    file_bytes = uf.read()
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆUUID + æ‹¡å¼µå­ï¼‰
                    ext = uf.name.split('.')[-1].lower() if '.' in uf.name else 'jpg'
                    safe_name = f"{uuid.uuid4().hex[:12]}.{ext}"
                    remote_path = f"{product_id}/competitors/comp_{comp_idx}/{safe_name}"
                    
                    url = data_store.upload_image(file_bytes, remote_path, bucket_name="lp-generator-images")
                    if url and url not in remote_urls:
                        remote_urls.append(url)
                except Exception as e:
                    st.error(f"Supabaseã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            comp_data["file_urls"] = remote_urls
        
        competitors[comp_idx] = comp_data
        current_data["competitors"] = competitors
        product["competitor_analysis_v2"] = current_data
        
        # DBä¿å­˜
        if data_store.update_product(product_id, product):
            # Session Stateã®åŒæœŸ
            st.session_state[f"comp_files_paths_{comp_idx}"] = comp_data.get("files", [])
            st.session_state[f"comp_file_urls_{comp_idx}"] = comp_data.get("file_urls", [])
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ã‚¯ãƒªã‚¢
            st.session_state[f"uploader_key_comp_{comp_idx}"] += 1
            st.toast(f"ç«¶åˆ{comp_idx+1}: ã™ã¹ã¦ã®ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ", icon="âœ…")
            st.rerun()


def save_competitor_field(product_id, data_store, comp_idx, field_name):
    """ç‰¹å®šã®ç«¶åˆã®ç‰¹å®šãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ã‘ã‚’DBã«ä¿å­˜"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å¯¾å¿œã™ã‚‹ã‚­ãƒ¼åã‚’å–å¾—
    session_key = f"comp_{field_name}_{comp_idx}"
    if field_name == "files":
        session_key = f"comp_files_paths_{comp_idx}"
    elif field_name == "file_urls":
        session_key = f"comp_file_urls_{comp_idx}"
        
    new_value = st.session_state.get(session_key)
    if new_value is None:
        return

    # DBã‹ã‚‰æœ€æ–°çŠ¶æ…‹ã‚’å–å¾—ã—ã¦ãƒãƒ¼ã‚¸
    product = data_store.get_product(product_id) or {}
    current_data = product.get("competitor_analysis_v2") or {}
    competitors = (current_data.get("competitors") or []).copy()

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ•´åˆæ€§ç¢ºä¿
    while len(competitors) <= comp_idx:
        competitors.append({
            "name": f"ç«¶åˆ{len(competitors)+1}", 
            "text": "", 
            "files": [], 
            "file_urls": []
        })

    # è©²å½“ã™ã‚‹ç«¶åˆã®æŒ‡å®šãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ã‘ã‚’æ›´æ–°
    competitors[comp_idx][field_name] = new_value

    current_data["competitors"] = competitors
    product["competitor_analysis_v2"] = current_data
    
    if data_store.update_product(product_id, product):
        st.toast(f"ä¿å­˜å®Œäº†: {competitors[comp_idx].get('name', 'ç«¶åˆ')}")

def save_competitor_text(product_id, competitor_index, data_store):
    """ç«¶åˆãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•ä¿å­˜"""
    key = f"comp_text_{competitor_index}"
    if key in st.session_state:
        text = st.session_state[key]
        product = data_store.get_product(product_id)
        if product:
            current_data = product.get("competitor_analysis_v2") or {}
            competitors = (current_data.get("competitors") or []).copy()
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ•´åˆæ€§ç¢ºä¿
            while len(competitors) <= competitor_index:
                competitors.append({
                    "name": f"ç«¶åˆ{len(competitors)+1}", 
                    "text": "", 
                    "files": [], 
                    "file_urls": []
                })
            
            competitors[competitor_index]['text'] = text
            current_data["competitors"] = competitors
            product["competitor_analysis_v2"] = current_data
            
            if data_store.update_product(product_id, product):
                st.toast(f"ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {competitors[competitor_index].get('name', 'ç«¶åˆ')}")

def render_competitor_analysis(data_store, product_id):
    '''ç«¶åˆæƒ…å ±åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">ç«¶åˆæƒ…å ±</div>', unsafe_allow_html=True)
    st.caption("ç«¶åˆã”ã¨ã«ç”»åƒãƒ»ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ è¨´æ±‚è¦ç´ ã‚’è‡ªå‹•æŠ½å‡º")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ï¼ˆä¿å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å¾©å…ƒï¼‰
    # ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆIDãŒå¤‰ã‚ã£ãŸå ´åˆã‚‚åˆæœŸåŒ–ã‚’è¡Œã†
    if "competitor_count" not in st.session_state or st.session_state.get("last_product_id") != product_id:
        st.session_state.last_product_id = product_id
        # DBã‹ã‚‰ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        product = data_store.get_product(product_id)
        saved_competitors = []
        if product:
            saved_competitors = (product.get("competitor_analysis_v2") or {}).get("competitors", [])
        
        if saved_competitors:
            st.session_state.competitor_count = len(saved_competitors)
            for i, comp in enumerate(saved_competitors):
                st.session_state[f"comp_name_{i}"] = comp.get("name", f"ç«¶åˆ{i+1}")
                st.session_state[f"comp_text_{i}"] = comp.get("text", "")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å¾©å…ƒ
                if "files" in comp:
                    st.session_state[f"comp_files_paths_{i}"] = (comp.get("files") or [])
                
                # Supabase URLã®å¾©å…ƒ
                if "file_urls" in comp:
                    st.session_state[f"comp_file_urls_{i}"] = (comp.get("file_urls") or [])
        else:
            st.session_state.competitor_count = 1
    
    # ç«¶åˆè¿½åŠ ãƒœã‚¿ãƒ³
    col_add, col_space = st.columns([1, 3])
    with col_add:
        if st.button("ç«¶åˆã‚’è¿½åŠ ", key="add_competitor"):
            if st.session_state.competitor_count < 10:
                st.session_state.competitor_count += 1
                st.rerun()
            else:
                st.warning("æœ€å¤§10ç¤¾ã¾ã§ã§ã™")
    
    st.markdown("---")
    
    # å„ç«¶åˆã®å…¥åŠ›ã‚¨ãƒªã‚¢
    for i in range(st.session_state.competitor_count):
        with st.expander(f"ç«¶åˆ{i+1}", expanded=False):
            # å‰Šé™¤ãƒœã‚¿ãƒ³ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼æ¨ªã«ã¯ç½®ã‘ãªã„ã®ã§expanderå†…ï¼‰
            col_del_btn, _ = st.columns([1, 5])
            with col_del_btn:
                if st.button("ã“ã®ç«¶åˆã‚’å‰Šé™¤", key=f"del_comp_{i}"):
                    delete_competitor(product_id, data_store, i)
            
            # ã‚­ãƒ¼ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®æº–å‚™
            name_key = f"comp_name_{i}"
            default_name = f"ç«¶åˆ{i+1}"
            if name_key not in st.session_state:
                st.session_state[name_key] = default_name

            comp_name = st.text_input(
                "ç«¶åˆå",
                # valueå¼•æ•°ã¯å‰Šé™¤ï¼ˆsession_stateå„ªå…ˆï¼‰
                key=name_key,
                placeholder="ä¾‹: Aç¤¾ã€Bç¤¾",
                on_change=save_competitor_field,
                args=(product_id, data_store, i, "name")
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ç”»åƒï¼ˆæœ€å¤§30æšï¼‰**")
                
                # ä¿å­˜æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
                # 1. URLå„ªå…ˆ
                saved_urls = st.session_state.get(f"comp_file_urls_{i}") or []
                # 2. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                saved_local = st.session_state.get(f"comp_files_paths_{i}") or []

                # ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã‚­ãƒ¼ã«ã‚ˆã‚‹ãƒªã‚»ãƒƒãƒˆå¯¾å¿œ
                if f"uploader_key_comp_{i}" not in st.session_state:
                    st.session_state[f"uploader_key_comp_{i}"] = 0
                
                uploader_key = f"comp_files_{i}_{st.session_state[f'uploader_key_comp_{i}']}"
                
                uploaded_files = st.file_uploader(
                    "LPç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                    type=['png', 'jpg', 'jpeg'],
                    accept_multiple_files=True,
                    key=uploader_key,
                    label_visibility="collapsed",
                    on_change=handle_competitor_upload,
                    args=(product_id, data_store, i)
                )
                
                # è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆã®çµ±åˆ
                display_images = []
                # URLã‚’å„ªå…ˆ
                for url in saved_urls:
                    display_images.append({"type": "url", "path": url})
                
                # Supabaseæœªä½¿ç”¨æ™‚ã®ã¿ãƒ­ãƒ¼ã‚«ãƒ«ã‚’è¡¨ç¤º
                if not data_store.use_supabase:
                    for lp in saved_local:
                        if Path(lp).exists():
                            display_images.append({"type": "local", "path": lp})
                
                # è¡¨ç¤º
                if display_images:
                    st.caption(f"{len(display_images)}æš")
                    preview_cols = st.columns(6)
                    for idx, img in enumerate(display_images[:6]):
                        with preview_cols[idx % 6]:
                            st.image(img["path"], width=80)
                    if len(display_images) > 6:
                        st.caption(f"ä»– {len(display_images) - 6}æš")
            
                # ã‚­ãƒ¼ã®æº–å‚™
                text_key = f"comp_text_{i}"
                if text_key not in st.session_state:
                    st.session_state[text_key] = ""

                comp_text = st.text_area(
                    "ç«¶åˆã®LPæƒ…å ±ã‚’ã‚³ãƒ”ãƒš",
                    height=150,
                    key=text_key,
                    placeholder="ç«¶åˆå•†å“ãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±ã‚’ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆ...",
                    label_visibility="collapsed",
                    on_change=save_competitor_text,
                    args=(product_id, i, data_store)
                )
    
    st.markdown("---")
    
    # ä¸€æ‹¬åˆ†æãƒœã‚¿ãƒ³
    if st.button("ä¸€æ‹¬åˆ†æ", type="primary", use_container_width=True, key="analyze_all_competitors"):
        analyze_all_competitors(product_id, data_store)
    
    # åˆ†æçµæœè¡¨ç¤º
    product = data_store.get_product(product_id)
    if product and product.get("competitor_analysis_v2"):
        st.markdown("---")
        render_competitor_analysis_results(product["competitor_analysis_v2"])


def organize_keyword_data(product, data_store, product_id):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦åº¦é †ã«æ•´ç†"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.trace_viewer import save_with_trace
    
    st.write("DEBUG: é–¢æ•°é–‹å§‹")
    st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ProductãŒNoneã®å ´åˆã®ã‚¬ãƒ¼ãƒ‰
    if not product:
        product = {}

    with st.spinner("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¦åº¦ã‚’åˆ†æä¸­..."):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—åŒ–
            sheet_data = product.get("review_sheet_data") or {}
            st.write(f"DEBUG: sheet_data = {str(sheet_data)[:100]}...")
            raw_text = ""
            if isinstance(sheet_data, dict):
                data_type = sheet_data.get("type", "")
                sheet_content = sheet_data.get("content", "")
                
                if data_type in ["pdf", "text"]:
                    raw_text = str(sheet_content)
                    
                    # PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚ã®ã‚¨ãƒ©ãƒ¼æ–‡å­—ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã¯å†ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
                    if "PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“" in raw_text:
                        st.write("DEBUG: PDFå†ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œä¸­...")
                        file_path = product.get("review_sheet")
                        if file_path and os.path.exists(file_path):
                            from modules.file_parser import FileParser
                            parsed = FileParser().parse(file_path)
                            if parsed.get("content") != "PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“":
                                st.write("DEBUG: PDFå†ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
                                sheet_data = parsed
                                product["review_sheet_data"] = parsed
                                raw_text = str(parsed.get("content", ""))
                            else:
                                st.error("PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆpymupdfã¾ãŸã¯pypdfï¼‰ãŒã¾ã æœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                                return
                        else:
                            st.error("å…ƒã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                            return
                elif isinstance(sheet_content, list):
                    for item in sheet_content:
                        if isinstance(item, dict):
                            for k, v in item.items():
                                if v and str(v) not in ['nan', 'NaN', 'None', '']:
                                    raw_text += f"{k}: {v}\n"
                else:
                    raw_text = str(sheet_content)
            else:
                raw_text = str(sheet_data)
            
            st.write(f"DEBUG: raw_texté•·ã• = {len(raw_text)}")
            
            prompt = prompt_manager.get_prompt("keyword_organize", {
                "raw_data": raw_text[:3000]
            })
            st.write(f"DEBUG: promptå–å¾— = {bool(prompt)}")
            
            if not prompt:
                st.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ 'keyword_organize' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return

            st.write("DEBUG: AIçµæœå–å¾—ä¸­...")
            result = ai_provider.ask(prompt, "keyword_organize")
            st.write(f"DEBUG: AIçµæœ = {result[:100] if result else 'None'}")
            
            traced = save_with_trace(
                result=result,
                prompt_id="keyword_organize",
                prompt_used=prompt,
                input_refs={"ãƒ•ã‚¡ã‚¤ãƒ«": (product.get("review_sheet") or "")},
                model=settings.get("llm_model", "unknown")
            )
            
            product["keyword_organized"] = result
            product["keyword_organize_trace"] = traced

            st.write("DEBUG: DBä¿å­˜é–‹å§‹")
            if data_store.update_product(product_id, product):
                st.success("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æå®Œäº†ï¼")
                import time
                time.sleep(5)
                st.rerun()
            else:
                error_detail = getattr(data_store, 'last_error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
                st.error(f"DBæ›´æ–°å¤±æ•—: {error_detail}")
            
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")


def organize_sheet_data(product, data_store, product_id):
    """ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’AIã§æ•´ç†"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.trace_viewer import save_with_trace
    import time
    
    st.write("DEBUG: é–¢æ•°é–‹å§‹")
    st.info("ã‚·ãƒ¼ãƒˆæ•´ç†ã‚’é–‹å§‹ã—ã¾ã™...")

    # ProductãŒNoneã®å ´åˆã®ã‚¬ãƒ¼ãƒ‰
    if not product:
        product = {}
    
    with st.spinner("ã‚·ãƒ¼ãƒˆå†…å®¹ã‚’æ•´ç†ä¸­..."):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—åŒ–
            sheet_data = product.get("product_sheet_data") or {}
            st.write(f"DEBUG: sheet_data = {str(sheet_data)[:100]}...")
            raw_text = ""
            if isinstance(sheet_data, dict):
                data_type = sheet_data.get("type", "")
                content = sheet_data.get("content", "")
                
                if data_type in ["pdf", "text"]:
                    # PDF/ãƒ†ã‚­ã‚¹ãƒˆã¯ãã®ã¾ã¾
                    raw_text = str(content)
                    
                    # PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚ã®ã‚¨ãƒ©ãƒ¼æ–‡å­—ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã¯å†ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
                    if "PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“" in raw_text:
                        st.write("DEBUG: PDFå†ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œä¸­...")
                        file_path = product.get("product_sheet")
                        if file_path and os.path.exists(file_path):
                            from modules.file_parser import FileParser
                            parsed = FileParser().parse(file_path)
                            if parsed.get("content") != "PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“":
                                st.write("DEBUG: PDFå†ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
                                sheet_data = parsed
                                product["product_sheet_data"] = parsed
                                raw_text = str(parsed.get("content", ""))
                            else:
                                st.error("PDFãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆpymupdfã¾ãŸã¯pypdfï¼‰ãŒã¾ã æœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                                return
                        else:
                            st.error("å…ƒã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                            return
                elif isinstance(content, list):
                    # CSV/Excelã¯ãƒªã‚¹ãƒˆå½¢å¼
                    for item in content:
                        if isinstance(item, dict):
                            for k, v in item.items():
                                if v and str(v) not in ['nan', 'NaN', 'None', '']:
                                    raw_text += f"{k}: {v}\n"
                else:
                    raw_text = str(content)
            else:
                raw_text = str(sheet_data)
            
            st.write(f"DEBUG: raw_texté•·ã• = {len(raw_text)}")
            
            prompt = prompt_manager.get_prompt("sheet_organize", {
                "raw_data": raw_text[:3000]
            })
            st.write(f"DEBUG: promptå–å¾— = {bool(prompt)}")
            
            if not prompt:
                st.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ 'sheet_organize' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return

            result = ai_provider.ask(prompt, "sheet_organize")
            st.write(f"DEBUG: AIçµæœ = {result[:100] if result else 'None'}")
            
            # ãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãã§ä¿å­˜
            traced = save_with_trace(
                result=result,
                prompt_id="sheet_organize",
                prompt_used=prompt,
                input_refs={"ãƒ•ã‚¡ã‚¤ãƒ«": (product.get("product_sheet") or "")},
                model=settings.get("llm_model", "unknown")
            )
            
            product["product_sheet_organized"] = result
            product["product_sheet_organize_trace"] = traced
            
            st.write("DEBUG: DBä¿å­˜é–‹å§‹")
            if data_store.update_product(product_id, product):
                 st.success("æ•´ç†å®Œäº†ï¼")
                 time.sleep(5)
                 st.rerun()
            else:
                 error_detail = getattr(data_store, 'last_error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
                 st.error(f"DBæ›´æ–°å¤±æ•—: {error_detail}")
            
        except Exception as e:
            st.error(f"æ•´ç†ã‚¨ãƒ©ãƒ¼: {e}")


def analyze_competitor_text(text, product_id, data_store):
    '''ç«¶åˆãƒ†ã‚­ã‚¹ãƒˆã‚’AIã§åˆ†æ'''
    from modules.trace_viewer import save_with_trace
    with st.spinner('ç«¶åˆæƒ…å ±ã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            prompt = prompt_manager.get_prompt("competitor_analysis", {
                "competitor_text": text
            })
            
            result = ai_provider.ask(prompt, "competitor_analysis")
            
            # ãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãã§ä¿å­˜
            traced_result = save_with_trace(
                result=result,
                prompt_id="competitor_analysis",
                prompt_used=prompt,
                input_refs={"ç«¶åˆãƒ†ã‚­ã‚¹ãƒˆ": text[:200] + "..." if len(text) > 200 else text},
                model=settings.get("llm_model", settings.get("llm_provider", "unknown"))
            )
            
            product = data_store.get_product(product_id)
            if not product:
                product = {}
            product['competitor_analysis'] = traced_result
            data_store.update_product(product_id, product)
            
            st.success("åˆ†æå®Œäº†ï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def analyze_competitor_files(file_paths, product_id, data_store):
    '''ç«¶åˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPDF/ç”»åƒï¼‰ã‚’AIã§åˆ†æ'''
    with st.spinner('ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            
            all_analysis = []
            
            for file_path in file_paths:
                if file_path.lower().endswith('.pdf'):
                    # PDFã®å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                    file_parser = FileParser()
                    text = file_parser.parse(file_path)
                    if text:
                        prompt = f"""ä»¥ä¸‹ã®PDFæ–‡æ›¸ã®å†…å®¹ã‚’åˆ†æã—ã¦ã€ç«¶åˆå•†å“ã®æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

{text}

ã€å‡ºåŠ›å½¢å¼ã€‘
- è£½å“ã®ç‰¹å¾´
- ä¾¡æ ¼æƒ…å ±ï¼ˆã‚ã‚Œã°ï¼‰
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¡§å®¢
- è¨´æ±‚ãƒã‚¤ãƒ³ãƒˆ"""
                        result = ai_provider.generate_text(prompt)
                        all_analysis.append(f"ğŸ“„ {os.path.basename(file_path)}:\n{result}")
                
                elif file_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                    # ç”»åƒã®å ´åˆã¯Vision APIã§åˆ†æ
                    prompt_manager = PromptManager()
                    image_analyzer = ImageAnalyzer(ai_provider, prompt_manager)
                    result = image_analyzer.analyze_image(file_path)
                    all_analysis.append(f"ğŸ–¼ï¸ {os.path.basename(file_path)}:\n{result}")
            
            if all_analysis:
                combined_analysis = "\n\n---\n\n".join(all_analysis)
                
                # çµæœã‚’ä¿å­˜
                product = data_store.get_product(product_id)
                if not product:
                    product = {}
                product['competitor_analysis'] = combined_analysis
                data_store.update_product(product_id, product)
                
                st.success("åˆ†æå®Œäº†ï¼")
                st.rerun()
            else:
                st.warning("åˆ†æã§ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def analyze_all_competitors(product_id, data_store):
    """å…¨ç«¶åˆã‚’ä¸€æ‹¬åˆ†æï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºä»˜ãï¼‰"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.image_analyzer import ImageAnalyzer
    
    try:
        settings_manager = SettingsManager()
        settings = settings_manager.get_settings()
        ai_provider = AIProvider(settings)
        prompt_manager = PromptManager()
        image_analyzer = ImageAnalyzer(ai_provider, prompt_manager)
        
        # åˆ†æå¯¾è±¡ã‚’åé›†
        targets = []
        for i in range(st.session_state.competitor_count):
            comp_name = st.session_state.get(f"comp_name_{i}", f"ç«¶åˆ{i+1}")
            file_paths = st.session_state.get(f"comp_files_paths_{i}", [])
            file_urls = st.session_state.get(f"comp_file_urls_{i}", [])
            comp_text = st.session_state.get(f"comp_text_{i}", "")
            
            if file_paths or file_urls or comp_text.strip():
                targets.append({
                    "name": comp_name,
                    "files": file_paths,
                    "file_urls": file_urls,
                    "text": comp_text
                })
        
        if not targets:
            st.warning("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        results = []
        for idx, target in enumerate(targets):
            status_text.text(f"åˆ†æä¸­: {target['name']} ({idx+1}/{len(targets)})")
            progress_bar.progress((idx) / len(targets))
            
            result = image_analyzer.analyze_competitor(
                target["name"], 
                target["files"], 
                target["text"]
            )
            # URLã‚’æ›¸ãæˆ»ã—ï¼ˆåˆ†æçµæœã«å«ã¾ã‚Œãªã„ãŸã‚ï¼‰
            result["file_urls"] = target.get("file_urls", [])
            results.append(result)
        
        progress_bar.progress(1.0)
        status_text.text("é›†è¨ˆä¸­...")
        
        summary = image_analyzer.summarize_all_competitors(results)
        
        analysis_data = {
            "competitors": results,
            "summary": summary
        }
        
        product = data_store.get_product(product_id)
        if not product:
            product = {}
        product["competitor_analysis_v2"] = analysis_data
        data_store.update_product(product_id, product)
        
        status_text.empty()
        progress_bar.empty()
        st.success(f"{len(results)}ç¤¾ã®ç«¶åˆã‚’åˆ†æã—ã¾ã—ãŸ")
        st.rerun()
    
    except Exception as e:
        st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")


def render_competitor_analysis_results(analysis_data):
    """ç«¶åˆåˆ†æçµæœã‚’è¡¨ç¤º"""
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">åˆ†æçµæœ</div>', unsafe_allow_html=True)
    
    competitors = analysis_data.get("competitors", [])
    summary = analysis_data.get("summary", {})
    
    # å„ç«¶åˆã®çµæœ
    for comp in competitors:
        name = comp.get("name", "ä¸æ˜")
        img_count = comp.get("image_count", 0)
        has_text = comp.get("has_text", False)
        elements = comp.get("elements", [])
        
        source_info = []
        if img_count > 0:
            source_info.append(f"ç”»åƒ{img_count}æš")
        if has_text:
            source_info.append("ãƒ†ã‚­ã‚¹ãƒˆ")
        
        st.markdown(f"**â–  {name}** ({', '.join(source_info)})")
        if elements:
            st.markdown(", ".join(elements))
        else:
            st.markdown("_è¦ç´ ãªã—_")
        st.markdown("")
    
    # å…¨ä½“ã‚µãƒãƒªãƒ¼
    if summary.get("element_ranking"):
        st.markdown("---")
        st.subheader("å…¨ç«¶åˆã®è¨´æ±‚è¦ç´ ã¾ã¨ã‚")
        
        total = summary.get("total_competitors", 1)
        
        col1, col2 = st.columns(2)
        for i, (elem, count) in enumerate(summary["element_ranking"]):
            target_col = col1 if i % 2 == 0 else col2
            with target_col:
                if count == total:
                    st.markdown(f"âœ… **{elem}** ({count}/{total}ç¤¾) â† å¿…é ˆ")
                elif count >= total * 0.5:
                    st.markdown(f"âœ“ {elem} ({count}/{total}ç¤¾)")
                else:
                    st.markdown(f"ãƒ» {elem} ({count}/{total}ç¤¾)")


def save_product_sheet(product_id, data_store):
    product = data_store.get_product(product_id)
    if product and "edit_organized" in st.session_state:
        product["product_sheet_organized"] = st.session_state.edit_organized
        if data_store.update_product(product_id, product):
            st.toast("è£½å“ã‚·ãƒ¼ãƒˆæƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

def save_keyword_sheet(product_id, data_store):
    product = data_store.get_product(product_id)
    if product and "edit_keyword" in st.session_state:
        product["keyword_organized"] = st.session_state.edit_keyword
        if data_store.update_product(product_id, product):
            st.toast("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

def render_sheets_upload(data_store, product_id):
    '''å„ç¨®ã‚·ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        product_sheet = st.file_uploader(
            "è£½å“æƒ…å ±ã‚·ãƒ¼ãƒˆ",
            type=['xlsx', 'csv', 'pdf'],
            key="product_sheet"
        )
        
        if product_sheet:
            upload_dir = Path(f"data/uploads/{product_id}/sheets")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = upload_dir / f"product_sheet_{product_sheet.name}"
            with open(file_path, "wb") as f:
                f.write(product_sheet.getbuffer())
            
            file_parser = FileParser()
            try:
                parsed_data = file_parser.parse(str(file_path))
                
                product = data_store.get_product(product_id)
                if not product:
                    product = {}
                product['product_sheet'] = str(file_path)
                product['product_sheet_data'] = parsed_data
                data_store.update_product(product_id, product)
                
                st.success("è£½å“æƒ…å ±ã‚·ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿è¡¨ç¤º
        product = data_store.get_product(product_id)
        if product and product.get('product_sheet'):
            col_info, col_del = st.columns([4, 1])
            with col_info:
                st.info(f"ğŸ“„ {Path(product['product_sheet']).name}")
            with col_del:
                if st.button("å‰Šé™¤", key="del_product_sheet"):
                    product['product_sheet'] = None
                    product['product_sheet_data'] = None
                    product['product_sheet_organized'] = None
                    data_store.update_product(product_id, product)
                    st.rerun()
            
            # æ•´ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¡¨ç¤º
            organized = product.get("product_sheet_organized") or ""
            if organized:
                st.success("æ•´ç†æ¸ˆã¿")
                with st.expander("æ•´ç†æ¸ˆã¿å†…å®¹ã‚’ç¢ºèªãƒ»ç·¨é›†", expanded=False):
                    edited = st.text_area("å†…å®¹", value=organized, height=300, key="edit_organized", on_change=save_product_sheet, args=(product_id, data_store))
                    col_a, col_b = st.columns(2)
                    with col_a:
                        if st.button("å¤‰æ›´ã‚’ä¿å­˜", key="save_organized"):
                            product["product_sheet_organized"] = edited
                            data_store.update_product(product_id, product)
                            st.success("ä¿å­˜ã—ã¾ã—ãŸ")
                            st.rerun()
                    with col_b:
                        if st.button("å†æ•´ç†ï¼ˆAIï¼‰", key="reorganize_sheet"):
                            organize_sheet_data(product, data_store, product_id)
            else:
                if st.button("å†…å®¹ã‚’æ•´ç†ï¼ˆAIï¼‰", key="organize_sheet"):
                    organize_sheet_data(product, data_store, product_id)
    
    with col2:
        review_sheet = st.file_uploader(
            "ç«¶åˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆ",
            type=['xlsx', 'csv', 'pdf'],
            key="review_sheet"
        )
        
        if review_sheet:
            upload_dir = Path(f"data/uploads/{product_id}/sheets")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = upload_dir / f"review_sheet_{review_sheet.name}"
            with open(file_path, "wb") as f:
                f.write(review_sheet.getbuffer())
            
            file_parser = FileParser()
            try:
                parsed_data = file_parser.parse(str(file_path))
                
                product = data_store.get_product(product_id)
                if not product:
                    product = {}
                product['review_sheet'] = str(file_path)
                product['review_sheet_data'] = parsed_data
                data_store.update_product(product_id, product)
                
                st.success("ç«¶åˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿è¡¨ç¤º
        product = data_store.get_product(product_id)
        if product and product.get("review_sheet"):
            col_info, col_del = st.columns([4, 1])
            with col_info:
                st.info(f"ğŸ“„ {Path(product['review_sheet']).name}")
            with col_del:
                if st.button("å‰Šé™¤", key="del_review_sheet"):
                    product['review_sheet'] = None
                    product['review_sheet_data'] = None
                    product['keyword_organized'] = None
                    data_store.update_product(product_id, product)
                    st.rerun()
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•´ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¡¨ç¤º
            keyword_org = product.get("keyword_organized") or ""
            if keyword_org:
                with st.expander("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¦åº¦ï¼ˆç¢ºèªãƒ»ç·¨é›†ï¼‰", expanded=False):
                    edited = st.text_area("å†…å®¹", value=keyword_org, height=300, key="edit_keyword", on_change=save_keyword_sheet, args=(product_id, data_store))
                    col_a, col_b = st.columns(2)
                    with col_a:
                        if st.button("å¤‰æ›´ã‚’ä¿å­˜", key="save_keyword"):
                            product["keyword_organized"] = edited
                            data_store.update_product(product_id, product)
                            st.success("ä¿å­˜ã—ã¾ã—ãŸ")
                            st.rerun()
                    with col_b:
                        if st.button("å†åˆ†æ", key="reanalyze_keyword"):
                            organize_keyword_data(product, data_store, product_id)
            else:
                if st.button("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¦åº¦ã‚’åˆ†æ", key="analyze_keyword"):
                    organize_keyword_data(product, data_store, product_id)



def handle_lp_upload(product_id, data_store):
    """å‚è€ƒLPç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
    if "uploader_key_lp" not in st.session_state:
        st.session_state.uploader_key_lp = 0
    
    key = f"lp_images_{st.session_state.uploader_key_lp}"
    lp_images = st.session_state.get(key)
    
    if lp_images:
        image_paths = []
        # Supabaseä½¿ç”¨æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã‚’å›é¿
        if not data_store.use_supabase:
            upload_dir = Path(f"data/uploads/{product_id}/reference_lp")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            for uploaded_file in lp_images:
                file_path = upload_dir / uploaded_file.name
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                image_paths.append(str(file_path))
                st.toast(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            product = data_store.get_product(product_id) or {}
            existing = product.get('reference_lp_images') or []
            for path in image_paths:
                if path not in existing:
                    existing.append(path)
            product['reference_lp_images'] = existing
        
        # Supabaseç”¨ã®è£½å“æƒ…å ±å–å¾—
        if data_store.use_supabase:
            product = data_store.get_product(product_id) or {}
        
        # Supabase Storageã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if data_store.use_supabase:
            remote_urls = product.get('reference_lp_image_urls') or []
            uploaded_count = 0
            for uploaded_file in lp_images:
                try:
                    uploaded_file.seek(0)
                    file_bytes = uploaded_file.read()
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆUUID + æ‹¡å¼µå­ï¼‰
                    ext = uploaded_file.name.split('.')[-1].lower() if '.' in uploaded_file.name else 'jpg'
                    safe_name = f"{uuid.uuid4().hex[:12]}.{ext}"
                    remote_path = f"{product_id}/reference_lp/{safe_name}"
                    
                    url = data_store.upload_image(file_bytes, remote_path, bucket_name="lp-generator-images")
                    
                    if url:
                        # æ–‡å­—åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
                        if not isinstance(url, str) and hasattr(url, 'public_url'):
                            url = url.public_url
                        
                        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                        if url and url not in remote_urls:
                            remote_urls.append(url)
                            uploaded_count += 1
                except Exception as e:
                    st.error(f"Supabaseã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ ({uploaded_file.name}): {e}")
            
            if uploaded_count > 0:
                st.toast(f"{uploaded_count}æšã®ç”»åƒã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
            # ä¿å­˜å‰ã«é‡è¤‡ã‚’é™¤å»
            remote_urls = list(dict.fromkeys(remote_urls))
            product['reference_lp_image_urls'] = remote_urls
        

        if data_store.update_product(product_id, product):
            pass
        else:
            st.error("è£½å“æƒ…å ±ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # æ¬¡å›ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ã«ãƒ•ã‚©ãƒ¼ãƒ ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãŸã‚ã«ã‚­ãƒ¼ã‚’æ›´æ–°
        st.session_state.uploader_key_lp += 1


def handle_tone_upload(product_id, data_store):
    """ãƒˆãƒ³ãƒãƒŠç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
    if "uploader_key_tone" not in st.session_state:
        st.session_state.uploader_key_tone = 0
        
    key = f"tone_images_{st.session_state.uploader_key_tone}"
    tone_images = st.session_state.get(key)
    
    if tone_images:
        # Supabaseä½¿ç”¨æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã‚’å›é¿
        if not data_store.use_supabase:
            upload_dir = Path(f"data/uploads/{product_id}/tone_manner")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            image_paths = []
            for uploaded_file in tone_images:
                file_path = upload_dir / uploaded_file.name
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                image_paths.append(str(file_path))
                st.toast(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
            
            product = data_store.get_product(product_id) or {}
            
            existing = product.get('tone_manner_images') or []
            for path in image_paths:
                if path not in existing:
                    existing.append(path)
            product['tone_manner_images'] = existing
        
        if data_store.use_supabase:
            product = data_store.get_product(product_id) or {} # Re-fetch product if not already fetched for Supabase
            remote_urls = product.get('tone_manner_image_urls') or []
            uploaded_count = 0
            for uploaded_file in tone_images:
                try:
                    uploaded_file.seek(0)
                    file_bytes = uploaded_file.read()
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆUUID + æ‹¡å¼µå­ï¼‰
                    ext = uploaded_file.name.split('.')[-1].lower() if '.' in uploaded_file.name else 'jpg'
                    safe_name = f"{uuid.uuid4().hex[:12]}.{ext}"
                    remote_path = f"{product_id}/tone_manner/{safe_name}"
                    
                    url = data_store.upload_image(file_bytes, remote_path, bucket_name="lp-generator-images")
                    
                    if url:
                        # æ–‡å­—åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
                        if not isinstance(url, str) and hasattr(url, 'public_url'):
                            url = url.public_url

                        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                        if url and url not in remote_urls:
                            remote_urls.append(url)
                            uploaded_count += 1
                except Exception as e:
                    st.error(f"Supabaseã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ ({uploaded_file.name}): {e}")
            
            if uploaded_count > 0:
                st.toast(f"{uploaded_count}æšã®ç”»åƒã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
            # ä¿å­˜å‰ã«é‡è¤‡ã‚’é™¤å»
            remote_urls = list(dict.fromkeys(remote_urls))
            product['tone_manner_image_urls'] = remote_urls
        
        if data_store.update_product(product_id, product):
            pass
        else:
            st.error("è£½å“æƒ…å ±ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        st.session_state.uploader_key_tone += 1

def render_reference_images_upload(data_store, product_id):
    '''å‚è€ƒç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'''
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">å‚è€ƒç”»åƒ</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**å‚è€ƒLPç”»åƒ**")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚­ãƒ¼ã‚’ç®¡ç†
        if "uploader_key_lp" not in st.session_state:
            st.session_state.uploader_key_lp = 0
            
        lp_images = st.file_uploader(
            "å‚è€ƒLPç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=['png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            key=f"lp_images_{st.session_state.uploader_key_lp}",
            on_change=handle_lp_upload,
            args=(product_id, data_store)
        )

        # ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
        st.markdown("---")
        lp_presets = data_store.get_presets('reference_lp')
        lp_preset_options = ["ãªã—"] + [p['name'] for p in lp_presets]
        selected_lp_preset = st.selectbox("ãƒ—ãƒªã‚»ãƒƒãƒˆã‹ã‚‰é¸æŠ", lp_preset_options, key="ref_lp_preset")

        if selected_lp_preset != "ãªã—":
            preset = next((p for p in lp_presets if p['name'] == selected_lp_preset), None)
            if preset:
                images = get_valid_image_urls(preset.get('images') or [])
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                if images:
                    st.write(f"**ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ{len(images)}æšï¼‰**")
                    preview_cols = st.columns(min(len(images), 5))
                    for i, img_url in enumerate(images[:5]):
                        with preview_cols[i]:
                            try:
                                st.image(img_url, width=100)
                            except:
                                st.write("âš ï¸ èª­è¾¼ã‚¨ãƒ©ãƒ¼")
                    if len(images) > 5:
                        st.caption(f"ä»– {len(images) - 5} æš...")
                
                # é©ç”¨ãƒœã‚¿ãƒ³
                if st.button("ã“ã®ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é©ç”¨", key="apply_ref_preset", use_container_width=True):
                    product = data_store.get_product(product_id) or {}
                    product['reference_lp_image_urls'] = images
                    data_store.update_product(product_id, product)
                    st.success(f"ãƒ—ãƒªã‚»ãƒƒãƒˆã€Œ{selected_lp_preset}ã€ã‚’é©ç”¨ã—ã¾ã—ãŸ")
                    st.rerun()

        # ãƒ—ãƒªã‚»ãƒƒãƒˆç®¡ç†
        if lp_presets:
            with st.expander("ğŸ—‘ï¸ ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ç®¡ç†"):
                for p in lp_presets:
                    col_m1, col_m2 = st.columns([4, 1])
                    with col_m1:
                        st.write(f"ğŸ“ {p['name']}ï¼ˆ{len(p.get('images', []))}æšï¼‰")
                    with col_m2:
                        if st.button("å‰Šé™¤", key=f"del_ref_preset_{p['id']}"):
                            data_store.delete_preset_with_images(p['id'], p.get('images', []))
                            st.success(f"ã€Œ{p['name']}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                            st.rerun()

        # ç¾åœ¨ã®ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆä¿å­˜
        current_lp_images = (data_store.get_product(product_id) or {}).get('reference_lp_image_urls') or []
        # æœ‰åŠ¹ãªURLã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
        valid_lp_images = [url for url in current_lp_images if url and isinstance(url, str) and url.startswith('http')]

        if valid_lp_images:
            with st.expander("ğŸ’¾ ç¾åœ¨ã®ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆã¨ã—ã¦ä¿å­˜"):
                new_lp_preset_name = st.text_input("ãƒ—ãƒªã‚»ãƒƒãƒˆåï¼ˆå¿…é ˆï¼‰", key="new_ref_preset_name")
                if st.button("ä¿å­˜", key="save_ref_preset"):
                    if not new_lp_preset_name.strip():
                        st.error("ãƒ—ãƒªã‚»ãƒƒãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    else:
                        # åŒåãƒã‚§ãƒƒã‚¯
                        existing = [p for p in lp_presets if p['name'] == new_lp_preset_name.strip()]
                        if existing:
                            st.warning(f"ã€Œ{new_lp_preset_name}ã€ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚åˆ¥ã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        else:
                            with st.spinner("ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆç”¨ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚³ãƒ”ãƒ¼ä¸­..."):
                                # ãƒ—ãƒªã‚»ãƒƒãƒˆç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
                                preset_id_short = uuid.uuid4().hex[:12]
                                preset_folder = f"presets/{preset_id_short}"
                                
                                # ç¾åœ¨ã®ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«ã‚³ãƒ”ãƒ¼
                                copied_urls = []
                                for img_url in valid_lp_images:
                                    try:
                                        # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                                        response = requests.get(img_url)
                                        if response.status_code == 200:
                                            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                                            extension = img_url.split('.')[-1].split('?')[0]
                                            if len(extension) > 5: extension = 'jpg' # ç•°å¸¸ãªæ‹¡å¼µå­å¯¾ç­–
                                            new_filename = f"{uuid.uuid4().hex[:12]}.{extension}"
                                            new_path = f"{preset_folder}/{new_filename}"
                                            
                                            # ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                                            new_url = data_store.upload_image(
                                                response.content, 
                                                new_path, 
                                                bucket_name="lp-generator-images"
                                            )
                                            if new_url:
                                                copied_urls.append(new_url)
                                    except Exception as e:
                                        st.warning(f"ç”»åƒã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—: {e}")
                                
                                if copied_urls:
                                    # ã‚³ãƒ”ãƒ¼ã—ãŸURLã§ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä¿å­˜
                                    data_store.save_preset(new_lp_preset_name.strip(), 'reference_lp', copied_urls)
                                    st.success(f"âœ… ãƒ—ãƒªã‚»ãƒƒãƒˆã€Œ{new_lp_preset_name}ã€ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆ{len(copied_urls)}æšï¼‰")
                                    st.rerun()
                                else:
                                    st.error("ç”»åƒã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ")

        st.markdown("---")

    
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿å‚è€ƒLPç”»åƒè¡¨ç¤ºï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰URLå„ªå…ˆï¼‰
        product = data_store.get_product(product_id)
        # URLãƒªã‚¹ãƒˆã¨ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ãƒªã‚¹ãƒˆã‚’çµ±åˆã—ã¦è¡¨ç¤ºå¯¾è±¡ã«ã™ã‚‹
        display_images = []
        
        # URLãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆ
        if product and product.get("reference_lp_image_urls"):
            valid_urls = get_valid_image_urls(product["reference_lp_image_urls"])
            display_images.extend([{"type": "url", "path": url} for url in valid_urls])
        
        # Supabaseæœªä½¿ç”¨æ™‚ã®ã¿ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’è¡¨ç¤º
        if not data_store.use_supabase:
            if product and product.get("reference_lp_images"):
                for img in product["reference_lp_images"]:
                    if Path(img).exists():
                         display_images.append({"type": "local", "path": img})

        if display_images:
            st.markdown("**ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿:**")
            render_images_with_bulk_delete(display_images, "reference_lp", product_id, data_store)
        
        # LPåˆ†æçµæœè¡¨ç¤º
        from modules.trace_viewer import show_trace
        if product.get("lp_analyses"):
            st.markdown("**LPåˆ†æçµæœ:**")
            for i, analysis in enumerate(product["lp_analyses"]):
                with st.expander(f"ğŸ“„ {i+1}æšç›®ã®åˆ†æ", expanded=False):
                    if isinstance(analysis, dict) and "result" in analysis:
                        from modules.trace_viewer import show_lp_analysis
                        show_lp_analysis(analysis)
                        
                        # å†åˆ†æãƒœã‚¿ãƒ³
                        if st.button(f"ğŸ”„ å†åˆ†æ", key=f"reanalyze_lp_{i}"):
                            reanalyze_lp_image(product, data_store, product_id, i)
                        
                        # ç·¨é›†ãƒ¢ãƒ¼ãƒ‰
                        if st.checkbox("ç·¨é›†ã™ã‚‹", key=f"edit_lp_{i}"):
                            result = analysis["result"]
                            
                            # ãƒšãƒ¼ã‚¸ç¨®åˆ¥
                            page_types = ["ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼", "æ©Ÿèƒ½èª¬æ˜", "æ¯”è¼ƒè¡¨", "å£ã‚³ãƒŸ", "CTA", "ãã®ä»–"]
                            current_type = result.get("page_type", "ãã®ä»–")
                            idx = page_types.index(current_type) if current_type in page_types else 5
                            new_type = st.selectbox("ãƒšãƒ¼ã‚¸ç¨®åˆ¥", page_types, index=idx, key=f"type_{i}")
                            result["page_type"] = new_type
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ç·¨é›†
                            st.markdown("**ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ **")
                            texts = result.get("texts", [])
                            for j, t in enumerate(texts):
                                cols = st.columns([2, 3, 1])
                                with cols[0]:
                                    t["type"] = st.text_input("ç¨®é¡", t.get("type", ""), key=f"tt_{i}_{j}")
                                with cols[1]:
                                    t["content"] = st.text_input("å†…å®¹", t.get("content", ""), key=f"tc_{i}_{j}")
                                with cols[2]:
                                    if st.button("ğŸ—‘ï¸", key=f"del_t_{i}_{j}"):
                                        texts.pop(j)
                                        data_store.update_product(product_id, product)
                                        st.rerun()
                            
                            if st.button("â• ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ ", key=f"add_t_{i}"):
                                texts.append({"type": "", "content": "", "char_count": 0, "position": "", "size": ""})
                                data_store.update_product(product_id, product)
                                st.rerun()
                            
                            if st.button("ğŸ’¾ ä¿å­˜", key=f"save_lp_{i}", type="primary"):
                                data_store.update_product(product_id, product)
                                st.success("ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
                        show_trace(analysis, f"{i+1}æšç›®ã®ç”Ÿæˆæƒ…å ±")
                    else:
                        st.write(analysis)
    
    with col2:
        st.write("**ãƒˆãƒ³ãƒãƒŠå‚è€ƒç”»åƒ**")
        
        if "uploader_key_tone" not in st.session_state:
            st.session_state.uploader_key_tone = 0
            
        tone_images = st.file_uploader(
            "ãƒˆãƒ³ãƒãƒŠå‚è€ƒç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=['png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            key=f"tone_images_{st.session_state.uploader_key_tone}",
            on_change=handle_tone_upload,
            args=(product_id, data_store)
        )

        # ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
        st.markdown("---")
        tm_presets = data_store.get_presets('tone_manner')
        tm_preset_options = ["ãªã—"] + [p['name'] for p in tm_presets]
        selected_tm_preset = st.selectbox("ãƒ—ãƒªã‚»ãƒƒãƒˆã‹ã‚‰é¸æŠ", tm_preset_options, key="tm_preset")

        if selected_tm_preset != "ãªã—":
            preset = next((p for p in tm_presets if p['name'] == selected_tm_preset), None)
            if preset:
                images = get_valid_image_urls(preset.get('images') or [])
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                if images:
                    st.write(f"**ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ{len(images)}æšï¼‰**")
                    preview_cols = st.columns(min(len(images), 5))
                    for i, img_url in enumerate(images[:5]):
                        with preview_cols[i]:
                            try:
                                st.image(img_url, width=100)
                            except:
                                st.write("âš ï¸ èª­è¾¼ã‚¨ãƒ©ãƒ¼")
                    if len(images) > 5:
                        st.caption(f"ä»– {len(images) - 5} æš...")
                
                # é©ç”¨ãƒœã‚¿ãƒ³
                if st.button("ã“ã®ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é©ç”¨", key="apply_tm_preset", use_container_width=True):
                    product = data_store.get_product(product_id) or {}
                    product['tone_manner_image_urls'] = images
                    data_store.update_product(product_id, product)
                    st.success(f"ãƒ—ãƒªã‚»ãƒƒãƒˆã€Œ{selected_tm_preset}ã€ã‚’é©ç”¨ã—ã¾ã—ãŸ")
                    st.rerun()

        # ãƒ—ãƒªã‚»ãƒƒãƒˆç®¡ç†
        if tm_presets:
            with st.expander("ğŸ—‘ï¸ ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ç®¡ç†"):
                for p in tm_presets:
                    col_tm1, col_tm2 = st.columns([4, 1])
                    with col_tm1:
                        st.write(f"ğŸ“ {p['name']}ï¼ˆ{len(p.get('images', []))}æšï¼‰")
                    with col_tm2:
                        if st.button("å‰Šé™¤", key=f"del_tm_preset_{p['id']}"):
                            data_store.delete_preset_with_images(p['id'], p.get('images', []))
                            st.success(f"ã€Œ{p['name']}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                            st.rerun()

        # ç¾åœ¨ã®ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆä¿å­˜
        current_tm_images = (data_store.get_product(product_id) or {}).get('tone_manner_image_urls') or []
        # æœ‰åŠ¹ãªURLã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
        valid_tm_images = [url for url in current_tm_images if url and isinstance(url, str) and url.startswith('http')]

        if valid_tm_images:
            with st.expander("ğŸ’¾ ç¾åœ¨ã®ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆã¨ã—ã¦ä¿å­˜"):
                new_tm_preset_name = st.text_input("ãƒ—ãƒªã‚»ãƒƒãƒˆåï¼ˆå¿…é ˆï¼‰", key="new_tm_preset_name")
                if st.button("ä¿å­˜", key="save_tm_preset"):
                    if not new_tm_preset_name.strip():
                        st.error("ãƒ—ãƒªã‚»ãƒƒãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    else:
                        # åŒåãƒã‚§ãƒƒã‚¯
                        existing = [p for p in tm_presets if p['name'] == new_tm_preset_name.strip()]
                        if existing:
                            st.warning(f"ã€Œ{new_tm_preset_name}ã€ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚åˆ¥ã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        else:
                            with st.spinner("ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆç”¨ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚³ãƒ”ãƒ¼ä¸­..."):
                                # ãƒ—ãƒªã‚»ãƒƒãƒˆç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
                                preset_id_short = uuid.uuid4().hex[:12]
                                preset_folder = f"presets/{preset_id_short}"
                                
                                # ç¾åœ¨ã®ç”»åƒã‚’ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«ã‚³ãƒ”ãƒ¼
                                copied_urls = []
                                for img_url in valid_tm_images:
                                    try:
                                        # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                                        response = requests.get(img_url)
                                        if response.status_code == 200:
                                            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                                            extension = img_url.split('.')[-1].split('?')[0]
                                            if len(extension) > 5: extension = 'jpg' # ç•°å¸¸ãªæ‹¡å¼µå­å¯¾ç­–
                                            new_filename = f"{uuid.uuid4().hex[:12]}.{extension}"
                                            new_path = f"{preset_folder}/{new_filename}"
                                            
                                            # ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                                            new_url = data_store.upload_image(
                                                response.content, 
                                                new_path, 
                                                bucket_name="lp-generator-images"
                                            )
                                            if new_url:
                                                copied_urls.append(new_url)
                                    except Exception as e:
                                        st.warning(f"ç”»åƒã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—: {e}")
                                
                                if copied_urls:
                                    # ã‚³ãƒ”ãƒ¼ã—ãŸURLã§ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä¿å­˜
                                    data_store.save_preset(new_tm_preset_name.strip(), 'tone_manner', copied_urls)
                                    st.success(f"ãƒ—ãƒªã‚»ãƒƒãƒˆã€Œ{new_tm_preset_name}ã€ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆ{len(copied_urls)}æšï¼‰")
                                    st.rerun()
                                else:
                                    st.error("ç”»åƒã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ")

        st.markdown("---")

        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒˆãƒ³ãƒãƒŠç”»åƒè¡¨ç¤ºï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰URLå„ªå…ˆï¼‰
        product = data_store.get_product(product_id)
        tm_display_images = []
        
        if product and product.get("tone_manner_image_urls"):
            valid_urls = get_valid_image_urls(product["tone_manner_image_urls"])
            tm_display_images.extend([{"type": "url", "path": url} for url in valid_urls])
            
        # Supabaseæœªä½¿ç”¨æ™‚ã®ã¿ãƒ­ãƒ¼ã‚«ãƒ«ã‚’è¡¨ç¤º
        if not data_store.use_supabase:
            if product and product.get("tone_manner_images"):
                for img in product["tone_manner_images"]:
                    if Path(img).exists():
                         tm_display_images.append({"type": "local", "path": img})

        if tm_display_images:
            st.markdown("**ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿:**")
            render_images_with_bulk_delete(tm_display_images, "tone_manner", product_id, data_store)
        
        # ãƒˆãƒ³ãƒãƒŠåˆ†æçµæœè¡¨ç¤º
        from modules.trace_viewer import show_trace
        if product and product.get("tone_manner"):
            st.markdown("**ğŸ¨ ãƒˆãƒ³ãƒãƒŠåˆ†æçµæœ:**")
            tone = product["tone_manner"]
            if isinstance(tone, dict) and "result" in tone:
                result = tone["result"]
                
                # ã‚«ãƒ©ãƒ¼è¡¨ç¤ºãƒ»ç·¨é›†
                colors = result.get("colors", {})
                if not colors: # colorsè¾æ›¸ãŒãªã„å ´åˆã®åˆæœŸåŒ–
                    colors = {
                        "main": tone.get("main_color", "#000000"),
                        "accent": tone.get("accent_color", "#000000"),
                        "background": tone.get("background_color", "#FFFFFF"),
                        "text": tone.get("text_color", "#000000")
                    }

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.write("ãƒ¡ã‚¤ãƒ³")
                    main_color = st.color_picker("ãƒ¡ã‚¤ãƒ³è‰²", colors.get("main", "#000000"), key="tm_main_edit", label_visibility="collapsed")
                    st.caption(main_color)
                with col2:
                    st.write("ã‚¢ã‚¯ã‚»ãƒ³ãƒˆ")
                    accent_color = st.color_picker("ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè‰²", colors.get("accent", "#000000"), key="tm_accent_edit", label_visibility="collapsed")
                    st.caption(accent_color)
                with col3:
                    st.write("èƒŒæ™¯")
                    bg_color = st.color_picker("èƒŒæ™¯è‰²", colors.get("background", "#FFFFFF"), key="tm_bg_edit", label_visibility="collapsed")
                    st.caption(bg_color)
                with col4:
                    st.write("ãƒ†ã‚­ã‚¹ãƒˆ")
                    text_color = st.color_picker("ãƒ†ã‚­ã‚¹ãƒˆè‰²", colors.get("text", "#000000"), key="tm_text_edit", label_visibility="collapsed")
                    st.caption(text_color)
                
                if st.button("ğŸ¨ ã‚«ãƒ©ãƒ¼è¨­å®šã‚’ä¿å­˜", width="stretch"):
                    # æ§‹é€ ã‚’ç¶­æŒã—ã¦ä¿å­˜
                    new_colors = {
                        "main": main_color,
                        "accent": accent_color,
                        "background": bg_color,
                        "text": text_color
                    }
                    result["colors"] = new_colors
                    tone["result"] = result
                    
                    # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®äº’æ›æ€§ç”¨ã‚­ãƒ¼ã‚‚æ›´æ–°
                    tone["main_color"] = main_color
                    tone["accent_color"] = accent_color
                    tone["background_color"] = bg_color
                    tone["text_color"] = text_color
                    
                    product['tone_manner'] = tone
                    data_store.update_product(product_id, product)
                    st.success("ã‚«ãƒ©ãƒ¼è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                    st.rerun()
                
                # ãƒ•ã‚©ãƒ³ãƒˆæƒ…å ±
                font = result.get("font", {})
                if font:
                    st.markdown(f"**ãƒ•ã‚©ãƒ³ãƒˆ:** {font.get('type', '')} / {font.get('weight', '')} / {font.get('style', '')}")
                
                # å…¨ä½“ã‚¹ã‚¿ã‚¤ãƒ«
                style = result.get("overall_style", {})
                if style:
                    st.markdown(f"**ã‚¹ã‚¿ã‚¤ãƒ«:** {style.get('impression', '')} / {style.get('target_gender', '')} / {style.get('target_age', '')}")
                
                show_trace(tone, "ãƒˆãƒ³ãƒãƒŠç”Ÿæˆæƒ…å ±")
            else:
                st.write(tone)
    
    
    if st.button("ğŸ¨ ãƒˆãƒ³ãƒãƒŠç”»åƒã‚’åˆ†æ", type="primary", width="stretch"):
        product = data_store.get_product(product_id)
        
        # ç”»åƒã‚½ãƒ¼ã‚¹ã‚’çµ±åˆï¼ˆURLå„ªå…ˆï¼‰
        tm_sources = []
        if product:
            # ã‚¯ãƒ©ã‚¦ãƒ‰ç”»åƒ
            tm_urls = product.get("tone_manner_image_urls") or []
            tm_sources.extend(get_valid_image_urls(tm_urls))
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ç”»åƒï¼ˆSupabaseæœªä½¿ç”¨æ™‚ã‚„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ï¼‰
            tm_locals = product.get("tone_manner_images") or []
            for path in tm_locals:
                if Path(path).exists() and path not in tm_sources:
                    tm_sources.append(path)
        
        if tm_sources:
            analyze_tone_manner_images(tm_sources, product_id, data_store)
        else:
            st.warning("ãƒˆãƒ³ãƒãƒŠç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    # ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã‚‰ç›´æ¥åˆ†æã‚’å®Ÿè¡Œ
    if st.button('ğŸ” å‚è€ƒç”»åƒã‹ã‚‰æ§‹æˆã‚’åˆ†æ', type='primary', width="stretch", key="btn_analyze_structure"):
        import traceback
        
        st.info("åˆ†æãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")
        product = data_store.get_product(product_id)
        
        # ç”»åƒã‚½ãƒ¼ã‚¹ã®ç‰¹å®šï¼ˆURLã¨ãƒ­ãƒ¼ã‚«ãƒ«ã‚’çµ±åˆï¼‰
        urls = product.get('reference_lp_image_urls') or []
        local = product.get('reference_lp_images') or []
        
        # URLå„ªå…ˆã€ãƒ•ã‚¡ã‚¤ãƒ«åã§é‡è¤‡æ’é™¤ï¼ˆç°¡æ˜“çš„ï¼‰
        seen_names = set()
        image_sources = []
        
        for url in urls:
            name = url.split('/')[-1].split('?')[0]
            if name not in seen_names:
                image_sources.append(url)
                seen_names.add(name)
        
        for path in local:
            name = Path(path).name
            if name not in seen_names:
                image_sources.append(path)
                seen_names.add(name)

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        with st.expander("ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=True):
            st.write(f"Product ID: {product_id}")
            st.write(f"Product Exists: {bool(product)}")
            st.write(f"URLs ({len(urls)}):", urls)
            st.write(f"Local ({len(local)}):", local)
            st.write(f"Final Sources ({len(image_sources)}):", image_sources)

        if not image_sources:
            st.error("âŒ åˆ†æå¯¾è±¡ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        try:
            # ä¾å­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            image_analyzer = ImageAnalyzer(ai_provider, prompt_manager)
            
            # åˆ†æå®Ÿè¡Œ
            st.write(f"å¯¾è±¡ç”»åƒ: {len(image_sources)}æš - åˆ†æä¸­...")
            analyze_reference_images(image_analyzer, image_sources, product_id, data_store)
            
        except Exception as e:
            st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.code(traceback.format_exc())


def analyze_tone_manner_images(image_paths, product_id, data_store):
    """ãƒˆãƒ³ãƒãƒŠç”»åƒã‚’åˆ†æï¼ˆè‰²ãƒ»ãƒ•ã‚©ãƒ³ãƒˆãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰"""
    from modules.trace_viewer import save_with_trace
    from modules.prompt_manager import PromptManager
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    import json
    
    with st.spinner('ãƒˆãƒ³ãƒãƒŠã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # æœ€åˆã®1æšã‚’ä»£è¡¨ã¨ã—ã¦åˆ†æ
            image_path = image_paths[0]
            prompt = prompt_manager.get_prompt("tone_manner_analysis", {})
            
            result = ai_provider.analyze_image(image_path, prompt)
            
            # JSONæŠ½å‡º
            try:
                if "```json" in result:
                    result = result.split("```json")[1].split("```")[0]
                elif "```" in result:
                    result = result.split("```")[1].split("```")[0]
                parsed = json.loads(result.strip())
            except:
                parsed = {"raw": result, "parse_error": True}
            
            # å®Ÿéš›ã«ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ï¼ˆç”»åƒåˆ†æç”¨ï¼‰
            task_models = settings.get("task_models", {})
            used_model = task_models.get("image_analysis", settings.get("llm_model", "unknown"))
            
            traced = save_with_trace(
                result=parsed,
                prompt_id="tone_manner_analysis",
                prompt_used=prompt,
                input_refs={"ç”»åƒ": Path(image_path).name},
                model=used_model
            )
            
            product = data_store.get_product(product_id)
            if not product:
                product = {}
            product['tone_manner'] = traced
            data_store.update_product(product_id, product)
            
            st.success("ãƒˆãƒ³ãƒãƒŠåˆ†æå®Œäº†")
            st.rerun()
            
        except Exception as e:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")


def reanalyze_lp_image(product, data_store, product_id, index):
    """ç‰¹å®šã®LPç”»åƒã‚’å†åˆ†æ"""
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    from modules.prompt_manager import PromptManager
    from modules.trace_viewer import save_with_trace
    import base64
    import json
    
    with st.spinner(f'{index+1}æšç›®ã‚’å†åˆ†æä¸­...'):
        try:
            lp_images = product.get('reference_lp_images') or []
            if index >= len(lp_images):
                st.error("ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            img_path = lp_images[index]
            
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            prompt = prompt_manager.get_prompt("lp_image_analysis", {})
            
            with open(img_path, "rb") as f:
                img_data = base64.b64encode(f.read()).decode()
            
            result = ai_provider.ask(prompt, "lp_image_analysis", images=[img_data])
            
            if isinstance(result, str):
                result = result.strip()
                if result.startswith("```"):
                    result = result.split("```")[1]
                    if result.startswith("json"):
                        result = result[4:]
                result = json.loads(result)
            
            # å®Ÿéš›ã«ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
            task_models = settings.get("task_models", {})
            used_model = task_models.get("image_analysis", settings.get("llm_model", "unknown"))
            
            traced = save_with_trace(
                result=result,
                prompt_id="lp_image_analysis",
                prompt_used=prompt,
                input_refs={"ç”»åƒ": img_path},
                model=used_model
            )
            
            # æ›´æ–°
            lp_analyses = product.get('lp_analyses') or []
            while len(lp_analyses) <= index:
                lp_analyses.append({})
            lp_analyses[index] = traced
            product['lp_analyses'] = lp_analyses
            data_store.update_product(product_id, product)
            
            st.success("å†åˆ†æå®Œäº†ï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"å†åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def analyze_reference_images(image_analyzer, image_paths, product_id, data_store):
    """å‚è€ƒLPç”»åƒã‚’1æšãšã¤è©³ç´°åˆ†æ"""
    from modules.trace_viewer import save_with_trace
    from modules.prompt_manager import PromptManager
    from modules.settings_manager import SettingsManager
    from modules.ai_provider import AIProvider
    import json
    
    with st.spinner('å‚è€ƒLPç”»åƒã‚’åˆ†æä¸­...'):
        try:
            settings_manager = SettingsManager()
            settings = settings_manager.get_settings()
            ai_provider = AIProvider(settings)
            prompt_manager = PromptManager()
            
            # æ—¢å­˜ã®åˆ†æçµæœã‚’å–å¾—
            product = data_store.get_product(product_id)
            existing_analyses = (product.get('lp_analyses_dict') or {}) if product else {}
            
            analyses = []
            status_text = st.empty()
            progress_bar = st.progress(0)
            
            for i, image_path in enumerate(image_paths):
                file_name = image_path.split('/')[-1].split('?')[0] if image_path.startswith('http') else Path(image_path).name
                
                # æ—¢ã«åˆ†ææ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
                if file_name in existing_analyses:
                    st.write(f"âœ… åˆ†ææ¸ˆã¿ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰: {file_name}")
                    analyses.append(existing_analyses[file_name])
                    progress_bar.progress((i + 1) / len(image_paths))
                    continue

                status_text.text(f"åˆ†æä¸­: {i+1}/{len(image_paths)}æšç›®... ({file_name})")
                progress_bar.progress((i) / len(image_paths))
                
                # ãƒ‘ã‚¹ã«ã‚ˆã‚‹å­˜åœ¨ç¢ºèªï¼ˆURLã§ãªã„ã€ã‹ã¤ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆï¼‰
                if not image_path.startswith("http") and not os.path.exists(image_path):
                    st.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {Path(image_path).name}")
                    st.warning("ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã¯éå»ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿æŒã•ã‚Œãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãŠæ‰‹æ•°ã§ã™ãŒã€å†åº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ç›´ã—ã¦ãã ã•ã„ã€‚")
                    continue
                
                try:
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
                    prompt = prompt_manager.get_prompt("lp_image_analysis", {})
                    
                    target_path = image_path
                    is_temp = False
                    
                    # URLã®å ´åˆã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    if image_path.startswith("http"):
                        try:
                            import requests
                            import tempfile
                            
                            response = requests.get(image_path, timeout=30)
                            if response.status_code == 200:
                                suffix = "." + image_path.split("/")[-1].split("?")[0].split(".")[-1]
                                if len(suffix) > 5 or "/" in suffix: # æ‹¡å¼µå­å–å¾—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                                    suffix = ".jpg"
                                    
                                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                                    tmp.write(response.content)
                                    target_path = tmp.name
                                    is_temp = True
                            else:
                                st.warning(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆStatus {response.status_code}ï¼‰: {file_name}")
                                continue
                        except Exception as dl_err:
                            st.warning(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {dl_err}")
                            continue

                    # ç”»åƒåˆ†æï¼ˆVision APIï¼‰
                    # ç”»åƒåˆ†æï¼ˆVision APIï¼‰
                    result = ai_provider.analyze_image(target_path, prompt)
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
                    if is_temp and os.path.exists(target_path):
                        try:
                            os.unlink(target_path)
                        except:
                            pass

                    # çµæœãƒã‚§ãƒƒã‚¯
                    if not result:
                        st.warning(f"ç”»åƒåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆçµæœãªã—ï¼‰: {file_name}")
                        continue
                    
                    # JSONæŠ½å‡º
                    try:
                        if "```json" in result:
                            result = result.split("```json")[1].split("```")[0]
                        elif "```" in result:
                            result = result.split("```")[1].split("```")[0]
                        parsed = json.loads(result.strip())
                    except Exception as e:
                        st.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {file_name} - {e}")
                        parsed = {"raw": result, "parse_error": True}
                    
                    # ãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãã§ä¿å­˜
                    traced = save_with_trace(
                        result=parsed,
                        prompt_id="lp_image_analysis",
                        prompt_used=prompt,
                        input_refs={"ç”»åƒ": Path(image_path).name, "é †ç•ª": i+1},
                        model=settings.get("llm_model", "unknown")
                    )
                    
                    # ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    analyses.append(traced)
                    
                    # ã€é‡è¦ã€‘1æšã”ã¨ã«å³æ™‚ä¿å­˜
                    product = data_store.get_product(product_id)
                    if product is None:
                        product = {}

                    current_dict = product.get('lp_analyses_dict') or {}
                    if current_dict is None:
                        current_dict = {}

                    current_dict[file_name] = traced
                    
                    product['lp_analyses_dict'] = current_dict
                    product['lp_analyses'] = list(current_dict.values())
                    
                    if data_store.update_product(product_id, product):
                         existing_analyses[file_name] = traced # ãƒ«ãƒ¼ãƒ—å†…ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚æ›´æ–°
                    else:
                         # ä¿å­˜å¤±æ•—æ™‚ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã•ãšç¶šè¡Œï¼ˆãƒ­ã‚°å‡ºåŠ›ç­‰ã¯æ¤œè¨ï¼‰
                         pass
                         
                except Exception as e:
                    st.warning(f"ç”»åƒåˆ†æã‚¹ã‚­ãƒƒãƒ—ï¼ˆ{Path(image_path).name}ï¼‰: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
                    if 'is_temp' in locals() and is_temp and 'target_path' in locals() and os.path.exists(target_path):
                        try:
                            os.unlink(target_path)
                        except:
                            pass

            # æœ€çµ‚çš„ãªå®Œäº†å‡¦ç†
            st.session_state.processing_reference_analysis = False
            st.success(f"å…¨{len(image_paths)}æšã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
            st.rerun()
                
        except Exception as e:
            st.session_state.processing_reference_analysis = False
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

# ãƒšãƒ¼ã‚¸å®Ÿè¡Œ
render_input_page()
