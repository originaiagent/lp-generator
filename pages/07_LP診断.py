import streamlit as st
import json
from modules.styles import apply_styles, page_header
from modules.ai_sidebar import render_ai_sidebar

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="LP Audit", layout="wide")

# ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨
apply_styles()

# AIã‚µã‚¤ãƒ‰ãƒãƒ¼è¡¨ç¤º
render_ai_sidebar()


from modules.page_guard import require_product
from modules.data_store import DataStore
from modules.ai_provider import AIProvider
from modules.settings_manager import SettingsManager

# è£½å“é¸æŠãƒã‚§ãƒƒã‚¯
require_product()

def get_lp_content(product, target_index=None):
    """LPã®æ§‹æˆã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’çµåˆã—ã¦æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™"""
    lp_text = ""
    
    # æ§‹æˆæƒ…å ±ã‚’å–å¾—
    raw_structure = product.get('structure', {})
    if isinstance(raw_structure, dict) and "result" in raw_structure:
        structure = raw_structure["result"]
    else:
        structure = raw_structure
    
    pages = structure.get('pages', []) if isinstance(structure, dict) else []
    page_contents = product.get('page_contents', {})
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼ˆ"å…¨ãƒšãƒ¼ã‚¸"ä»¥å¤–ï¼‰
    if target_index is not None and 0 <= target_index < len(pages):
        display_pages = [pages[target_index]]
        start_idx = target_index + 1
    else:
        display_pages = pages
        start_idx = 1
        
    for i, page in enumerate(display_pages):
        idx = start_idx + i if target_index is None else start_idx
        page_id = page.get('id', f"page_{idx}")
        title = page.get('title', 'ç„¡é¡Œ')
        role = page.get('role', page.get('summary', ''))
        
        lp_text += f"\n### P{idx}: {title}\n"
        lp_text += f"å½¹å‰²: {role}\n"
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
        content_item = page_contents.get(page_id, {})
        if isinstance(content_item, dict) and "result" in content_item:
            result_data = content_item["result"]
            if isinstance(result_data, dict) and "display" in result_data:
                page_text = result_data["display"]
            else:
                page_text = str(result_data)
        else:
            page_text = content_item.get('content', '') if isinstance(content_item, dict) else ""
            
        if page_text:
            lp_text += f"å†…å®¹:\n{page_text}\n"
        else:
            lp_text += "å†…å®¹: (æœªç”Ÿæˆ)\n"
            
    return lp_text

def generate_personas(ai_provider, product, exposure_type):
    """å•†å“ã¨éœ²å‡ºå…ˆã«å¿œã˜ãŸãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆ"""
    
    prompt = f"""
ã‚ãªãŸã¯ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚µãƒ¼ãƒã®å°‚é–€å®¶ã§ã™ã€‚

ã€å•†å“æƒ…å ±ã€‘
è£½å“å: {product.get('name', '')}
èª¬æ˜: {product.get('description', '')}
ã‚«ãƒ†ã‚´ãƒª: {product.get('category', '')}

ã€éœ²å‡ºå…ˆã€‘
{exposure_type}

ã€æŒ‡ç¤ºã€‘
ã“ã®å•†å“ã‚’{exposure_type}ã§è¦‹ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ã€ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®è³¼è²·æ¤œè¨è€…ã‚’3ã€œ4äººè¨­å®šã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®å¤šæ§˜æ€§ã‚’è€ƒæ…®ï¼š
- è³¼è²·æ„æ¬²: é«˜/ä¸­/ä½
- é‡è¦–ç‚¹: ä¾¡æ ¼/å“è³ª/æ™‚çŸ­/ãƒ‡ã‚¶ã‚¤ãƒ³/æ–°ã—ã•
- å•†å“ã¸ã®æ…‹åº¦: ç©æ¥µçš„/æ…é‡/æ‡ç–‘çš„

ã€å‡ºåŠ›å½¢å¼ã€‘JSONã®ã¿
{{
  "personas": [
    {{
      "name": "ãƒšãƒ«ã‚½ãƒŠã®çŸ­ã„èª¬æ˜ï¼ˆä¾‹ï¼š30ä»£ä¸»å©¦ãƒ»æ™‚çŸ­é‡è¦–ï¼‰",
      "age": "å¹´ä»£",
      "occupation": "è·æ¥­ãƒ»çŠ¶æ³",
      "motivation": "ã“ã®å•†å“ã‚’è¦‹ã¦ã„ã‚‹ç†ç”±",
      "concerns": "è³¼å…¥ã«ã‚ãŸã£ã¦ã®ä¸å®‰ãƒ»æ‡¸å¿µ",
      "decision_style": "è³¼è²·æ±ºå®šã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå³æ±º/æ¯”è¼ƒæ¤œè¨/æ…é‡ï¼‰",
      "budget_sensitivity": "ä¾¡æ ¼æ„Ÿåº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰"
    }}
  ]
}}
"""
    
    response = ai_provider.ask(prompt, "persona_generation")
    
    try:
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        if "```json" in response:
            json_str = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            json_str = response.split("```")[1].split("```")[0]
        else:
            json_str = response
            
        data = json.loads(json_str.strip())
        return data.get('personas', [])
    except Exception as e:
        st.error(f"ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.code(response)
        return []

def evaluate_by_persona(ai_provider, product, exposure_type, persona, lp_content):
    """å„ãƒšãƒ«ã‚½ãƒŠè¦–ç‚¹ã§LPã‚’è©•ä¾¡"""
    
    # ç«¶åˆæƒ…å ±ã‚’å–å¾—
    comp_v2 = product.get('competitor_analysis_v2', {})
    competitors = comp_v2.get('competitors', [])
    if not competitors:
        competitors = product.get('competitors', [])
    
    # éœ²å‡ºå…ˆåˆ¥ã®è©•ä¾¡é‡ç‚¹
    exposure_focus = {
        "ECãƒ¢ãƒ¼ãƒ«": """
- ç«¶åˆå•†å“ã¨ä¸¦ã‚“ã æ™‚ã«ã€Œã“ã‚ŒãŒã„ã„ã€ã¨æ€ãˆã‚‹å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚‹ã‹
- æ¯”è¼ƒæ¤œè¨ä¸­ã®äººãŒã€Œä»–ã‚ˆã‚Šè‰¯ã•ãã†ã€ã¨æ„Ÿã˜ã‚‹æ ¹æ‹ ãŒæ˜ç¢ºã‹
- ã€Œå¤±æ•—ã—ãŸããªã„ã€å¿ƒç†ã«å¯¾ã™ã‚‹å®‰å¿ƒææ–™ãŒã‚ã‚‹ã‹
""",
        "ã‚¯ãƒ©ãƒ•ã‚¡ãƒ³": """
- ã€Œã“ã‚“ãªã®åˆã‚ã¦è¦‹ãŸï¼ã€ã¨ã„ã†æ–°è¦æ€§ãƒ»é©šããŒã‚ã‚‹ã‹
- é–‹ç™ºè€…ã®æƒ³ã„ã‚„ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã«å…±æ„Ÿã§ãã‚‹ã‹
- ã€Œå¿œæ´ã—ãŸã„ã€ã¨æ€ãˆã‚‹ã‹
- æ—©æœŸæ”¯æ´è€…ã¸ã®ãƒ¡ãƒªãƒƒãƒˆãŒæ˜ç¢ºã‹
""",
        "è‡ªç¤¾EC": """
- ãƒ–ãƒ©ãƒ³ãƒ‰ã®ä¸–ç•Œè¦³ãƒ»ç¾æ„è­˜ãŒä¸€è²«ã—ã¦ã„ã‚‹ã‹
- ã€Œã“ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã‹ã‚‰è²·ã„ãŸã„ã€ã¨æ€ã‚ã›ã‚‹é­…åŠ›ãŒã‚ã‚‹ã‹
- ä»–ã®ECã‚µã‚¤ãƒˆã§ã¯ãªãè‡ªç¤¾ECã§è²·ã†ç†ç”±ãŒã‚ã‚‹ã‹
- ãƒ•ã‚¡ãƒ³ã«ãªã‚ŠãŸããªã‚‹è¦ç´ ãŒã‚ã‚‹ã‹
"""
    }
    
    prompt = f"""
ã‚ãªãŸã¯ä»¥ä¸‹ã®ãƒšãƒ«ã‚½ãƒŠã«ãªã‚Šãã£ã¦ã€ã“ã®LPã‚’è¦‹ãŸæ„Ÿæƒ³ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚

ã€ã‚ãªãŸã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€‘
{persona['name']}
å¹´ä»£: {persona['age']}
è·æ¥­: {persona['occupation']}
ã“ã®å•†å“ã‚’è¦‹ã¦ã„ã‚‹ç†ç”±: {persona['motivation']}
è³¼å…¥ã«ã‚ãŸã£ã¦ã®ä¸å®‰: {persona['concerns']}
è³¼è²·ã‚¹ã‚¿ã‚¤ãƒ«: {persona['decision_style']}
ä¾¡æ ¼æ„Ÿåº¦: {persona['budget_sensitivity']}

ã€éœ²å‡ºå…ˆã€‘
{exposure_type}

ã€ã“ã®éœ²å‡ºå…ˆã§ç‰¹ã«é‡è¦ãªè©•ä¾¡ãƒã‚¤ãƒ³ãƒˆã€‘
{exposure_focus.get(exposure_type, "")}

ã€LPå†…å®¹ã€‘
{lp_content}

ã€ç«¶åˆæƒ…å ±ã€‘
{str(competitors)[:1000]}

ã€æŒ‡ç¤ºã€‘
ã“ã®LPã‚’è¦‹ãŸç‡ç›´ãªæ„Ÿæƒ³ã‚’ã€ã“ã®ãƒšãƒ«ã‚½ãƒŠã®å£èª¿ã§è¿°ã¹ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘JSONã®ã¿
{{
  "overall_rating": 5æ®µéšè©•ä¾¡ï¼ˆ1-5ï¼‰,
  "purchase_decision": "è²·ã† / è¿·ã† / è²·ã‚ãªã„",
  "first_impression": "ç¬¬ä¸€å°è±¡ï¼ˆ3ç§’ã§æ„Ÿã˜ãŸã“ã¨ï¼‰",
  "voice": "ã“ã®ãƒšãƒ«ã‚½ãƒŠã®ç”Ÿã®å£°ï¼ˆ2-3æ–‡ã§è‡ªç„¶ãªå£èªä½“ã§ï¼‰",
  "resonated_points": ["éŸ¿ã„ãŸãƒã‚¤ãƒ³ãƒˆ1", "éŸ¿ã„ãŸãƒã‚¤ãƒ³ãƒˆ2"],
  "concerns": ["ä¸å®‰ãƒ»æ‡¸å¿µ1", "ä¸å®‰ãƒ»æ‡¸å¿µ2"],
  "vs_competitors": "ç«¶åˆã¨æ¯”ã¹ãŸå°è±¡ï¼ˆ1æ–‡ï¼‰",
  "improvement_suggestion": "ã“ã†ãªã£ã¦ãŸã‚‰è²·ã†ã®ã«ï¼ˆ1æ–‡ï¼‰"
}}
"""
    
    response = ai_provider.ask(prompt, "persona_evaluation")
    
    try:
        if "```json" in response:
            json_str = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            json_str = response.split("```")[1].split("```")[0]
        else:
            json_str = response
            
        return json.loads(json_str.strip())
    except Exception as e:
        st.error(f"è©•ä¾¡ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.code(response)
        return None

def generate_summary(ai_provider, evaluations, exposure_type):
    """å…¨ãƒšãƒ«ã‚½ãƒŠã®è©•ä¾¡ã‚’ç·åˆåˆ†æ"""
    
    prompt = f"""
ä»¥ä¸‹ã¯è¤‡æ•°ã®ãƒšãƒ«ã‚½ãƒŠã«ã‚ˆã‚‹LPè©•ä¾¡çµæœã§ã™ã€‚

ã€éœ²å‡ºå…ˆã€‘
{exposure_type}

ã€å„ãƒšãƒ«ã‚½ãƒŠã®è©•ä¾¡ã€‘
{json.dumps(evaluations, ensure_ascii=False, indent=2)}

ã€æŒ‡ç¤ºã€‘
ã“ã‚Œã‚‰ã®è©•ä¾¡ã‚’ç·åˆã—ã¦ã€LPã®æ”¹å–„ç‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘JSONã®ã¿
{{
  "purchase_rate": "è³¼å…¥æ¤œè¨ç‡ï¼ˆã€‡äººä¸­ã€‡äººï¼‰",
  "strengths": ["å¼·ã¿1", "å¼·ã¿2"],
  "weaknesses": ["å¼±ã¿1", "å¼±ã¿2"],
  "competitor_comparison": "ç«¶åˆã¨ã®æ¯”è¼ƒã§ã®å°è±¡",
  "improvements": [
    {{"priority": "é«˜", "content": "æ”¹å–„ç‚¹1"}},
    {{"priority": "ä¸­", "content": "æ”¹å–„ç‚¹2"}},
    {{"priority": "ä½", "content": "æ”¹å–„ç‚¹3"}}
  ],
  "overall_advice": "ç·åˆã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆ2-3æ–‡ï¼‰"
}}
"""
    
    response = ai_provider.ask(prompt, "diagnosis_summary")
    
    try:
        if "```json" in response:
            json_str = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            json_str = response.split("```")[1].split("```")[0]
        else:
            json_str = response
            
        return json.loads(json_str.strip())
    except Exception as e:
        st.error(f"ç·åˆåˆ†æã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.code(response)
        return None

def display_results(personas, evaluations, summary, exposure_type):
    """è¨ºæ–­çµæœã‚’è¡¨ç¤º"""
    
    st.markdown("---")
    st.subheader(f"ğŸ¯ {exposure_type}å‘ã‘è¨ºæ–­çµæœ")
    
    # ãƒšãƒ«ã‚½ãƒŠåˆ¥è©•ä¾¡
    st.markdown("### ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠåˆ¥è©•ä¾¡")
    
    for persona, eval_res in zip(personas, evaluations):
        if not eval_res:
            continue
            
        with st.expander(f"**{persona['name']}** - {'â­' * eval_res.get('overall_rating', 0)} {eval_res.get('purchase_decision', '')}", expanded=True):
            
            # ç¬¬ä¸€å°è±¡
            st.markdown(f"ğŸ‘€ **ç¬¬ä¸€å°è±¡:** {eval_res.get('first_impression', '')}")
            
            # ç”Ÿã®å£°
            st.markdown(f"ğŸ’¬ **ã“ã®äººã®å£°:**")
            st.info(eval_res.get('voice', ''))
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("âœ… **éŸ¿ã„ãŸç‚¹**")
                for point in eval_res.get('resonated_points', []):
                    st.write(f"ãƒ»{point}")
            with col2:
                st.markdown("âŒ **ä¸å®‰ãªç‚¹**")
                for concern in eval_res.get('concerns', []):
                    st.write(f"ãƒ»{concern}")
            
            st.caption(f"ç«¶åˆæ¯”è¼ƒ: {eval_res.get('vs_competitors', '')}")
            st.caption(f"æ”¹å–„å¸Œæœ›: {eval_res.get('improvement_suggestion', '')}")
    
    # ç·åˆåˆ†æ
    if summary:
        st.markdown("---")
        st.markdown("### ğŸ“Š ç·åˆåˆ†æ")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("è³¼å…¥æ¤œè¨ç‡", summary.get('purchase_rate', ''))
        with col2:
             st.markdown(f"**ğŸï¸ ç«¶åˆæ¯”è¼ƒ:** {summary.get('competitor_comparison', '')}")
        
        st.markdown("**ğŸ’ª å¼·ã¿**")
        for s in summary.get('strengths', []):
            st.write(f"ãƒ»{s}")
        
        st.markdown("**âš ï¸ å¼±ã¿**")
        for w in summary.get('weaknesses', []):
            st.write(f"ãƒ»{w}")
        
        st.markdown("**ğŸ”§ æ”¹å–„å„ªå…ˆåº¦**")
        for imp in summary.get('improvements', []):
            priority_icon = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(imp.get('priority'), "âšª")
            st.write(f"{priority_icon} [{imp.get('priority', '')}] {imp.get('content', '')}")
        
        st.markdown("**ğŸ’¡ ç·åˆã‚¢ãƒ‰ãƒã‚¤ã‚¹**")
        st.success(summary.get('overall_advice', ''))

def run_diagnosis(product, exposure_type, diagnosis_target):
    """LPè¨ºæ–­ã‚’å®Ÿè¡Œ"""
    
    data_store = DataStore()
    product_id = product.get('id')
    settings = SettingsManager().get_settings()
    ai_provider = AIProvider(settings)
    
    # è¨ºæ–­å¯¾è±¡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç‰¹å®š
    target_index = None
    if diagnosis_target != "å…¨ãƒšãƒ¼ã‚¸":
        try:
            # "P1 - ã‚¿ã‚¤ãƒˆãƒ«" ã®ã‚ˆã†ãªå½¢å¼ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŠ½å‡º
            target_index = int(diagnosis_target.split(' ')[0][1:]) - 1
        except:
            pass
            
    lp_content = get_lp_content(product, target_index)
    
    with st.spinner("ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆä¸­..."):
        personas = generate_personas(ai_provider, product, exposure_type)
    
    if not personas:
        st.error("ãƒšãƒ«ã‚½ãƒŠã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    evaluations = []
    progress_bar = st.progress(0)
    for i, persona in enumerate(personas):
        with st.spinner(f"ãƒšãƒ«ã‚½ãƒŠã€Œ{persona['name']}ã€è¦–ç‚¹ã§è©•ä¾¡ä¸­..."):
            eval_result = evaluate_by_persona(ai_provider, product, exposure_type, persona, lp_content)
            evaluations.append(eval_result)
        progress_bar.progress((i + 1) / len(personas))
    
    with st.spinner("ç·åˆåˆ†æä¸­..."):
        summary = generate_summary(ai_provider, evaluations, exposure_type)
    
    # çµæœã‚’è¡¨ç¤º
    display_results(personas, evaluations, summary, exposure_type)

    # è¨ºæ–­å®Œäº†å¾Œã€ä¿å­˜
    if product_id:
        diagnosis_res = data_store.save_diagnosis(
            product_id=product_id,
            exposure_type=exposure_type,
            personas=personas,
            evaluations=evaluations,
            summary=summary
        )
        if diagnosis_res:
            st.success("è¨ºæ–­çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        else:
            st.warning("è¨ºæ–­çµæœã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆSupabaseæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")

def render_diagnosis_page():
    page_header("LP Audit", "AIãƒšãƒ«ã‚½ãƒŠã«ã‚ˆã‚‹å®¢è¦³çš„ãªLPã®è¨ºæ–­ã¨åˆ†æ")

    data_store = DataStore()
    product_id = st.session_state.get('current_product_id')
    
    if not product_id:
        st.warning("è£½å“ã‚’é¸æŠã—ã¦ãã ã•ã„")
        st.stop()
        
    product = data_store.get_product(product_id)
    if not product:
        st.error("è£½å“æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        st.stop()

    # æœ€æ–°ã®è¨ºæ–­ã‚’è¡¨ç¤º
    latest = data_store.get_latest_diagnosis(product_id)
    if latest:
        st.info(f"æœ€çµ‚è¨ºæ–­: {latest['created_at'][:10]} - {latest['exposure_type']}")
        with st.expander("å‰å›ã®è¨ºæ–­çµæœã‚’è¦‹ã‚‹"):
            display_results(latest['personas'], latest['evaluations'], latest['summary'], latest['exposure_type'])

    st.subheader("è¨ºæ–­è¨­å®š")

    # éœ²å‡ºå…ˆé¸æŠ
    exposure_type = st.radio(
        "éœ²å‡ºå…ˆã‚’é¸æŠ",
        ["ECãƒ¢ãƒ¼ãƒ«", "ã‚¯ãƒ©ãƒ•ã‚¡ãƒ³", "è‡ªç¤¾EC"],
        horizontal=True,
        help="ã©ã“ã§è²©å£²ã™ã‚‹ã‹ã«ã‚ˆã£ã¦è©•ä¾¡åŸºæº–ãŒå¤‰ã‚ã‚Šã¾ã™"
    )

    # éœ²å‡ºå…ˆã®èª¬æ˜
    exposure_descriptions = {
        "ECãƒ¢ãƒ¼ãƒ«": "ğŸ›’ Amazonãƒ»æ¥½å¤©ãªã©ã€‚ç«¶åˆã¨æ¯”è¼ƒã•ã‚Œã‚‹ã“ã¨ãŒå‰æã€‚ã€Œãªãœã“ã‚Œã‚’é¸ã¶ã¹ãã‹ã€ãŒé‡è¦ã€‚",
        "ã‚¯ãƒ©ãƒ•ã‚¡ãƒ³": "ğŸš€ Makuakeãƒ»CAMPFIREãªã©ã€‚æ–°è¦æ€§ã¨å¿œæ´ã—ãŸããªã‚‹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãŒé‡è¦ã€‚",
        "è‡ªç¤¾EC": "ğŸ  è‡ªç¤¾ã‚µã‚¤ãƒˆã€‚ãƒ–ãƒ©ãƒ³ãƒ‰ã®ä¸–ç•Œè¦³ã¨ãƒ•ã‚¡ãƒ³åŒ–ãŒé‡è¦ã€‚"
    }
    st.info(exposure_descriptions[exposure_type])

    # è¨ºæ–­å¯¾è±¡é¸æŠ
    raw_structure = product.get('structure', {})
    if isinstance(raw_structure, dict) and "result" in raw_structure:
        structure = raw_structure["result"]
    else:
        structure = raw_structure
        
    pages = structure.get('pages', []) if isinstance(structure, dict) else []

    diagnosis_target = st.selectbox(
        "è¨ºæ–­å¯¾è±¡",
        ["å…¨ãƒšãƒ¼ã‚¸"] + [f"P{p.get('order', i+1)} - {p.get('title', 'ç„¡é¡Œ')}" for i, p in enumerate(pages)]
    )

    # è¨ºæ–­å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("è¨ºæ–­ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        run_diagnosis(product, exposure_type, diagnosis_target)

if __name__ == "__main__":
    render_diagnosis_page()
